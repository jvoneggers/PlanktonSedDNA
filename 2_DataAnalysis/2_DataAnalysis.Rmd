---
title: "Phytoplankton and zooplankton sedimentary DNA from Western United States"
author: "Jordan Von Eggers"
date: "`r Sys.Date()`"
output: pdf_document
editor_options: 
  chunk_output_type: console
---


# 0. Load packages, custom theme, color, and data
```{r}
library(phyloseq)
library(ggh4x) # facet_wrap2
library(lubridate) # Julian date in modelling 210Pb
library(patchwork) # if end up patching figures
library(Biostrings) # for blasting zooplankton
library(strucchange) # breakpoint analysis 
library(nlme) # linear mixed effects models
library(sf) # for map
library(raster) # for map
library(elevatr) # for elevation for map
library(tidyverse) # load last to avoid conflicts
```


```{r}
custom_theme <- function() {
  theme_bw() +
    theme(
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),  
      text = element_text(color = "black", size = 13),
      axis.text = element_text(color = "black",size = 13),
      axis.title = element_text(color = "black",size = 13),
      axis.title.x = element_text(margin = margin(t = 10)),
      axis.title.y = element_text(margin = margin(r = 10)),
      plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, size = 12),
      legend.text = element_text(size = 13),
      legend.title = element_text(size = 13,hjust = 0.5),
      strip.text = element_text(size = 13, color = "black"))}

# set colors for lakes
lake_colors <- c("Crescent" = "#EE6363", 
                 "Louise" = "#FFA07A",
                 "Monogram" = "darkgoldenrod1",
                 "Canyon" = "#b9ceac", 
                 "Eyrie" = "darkolivegreen3",
                 "Lightning" = "darkolivegreen",
                 "Scott" = "#008080",
                 "Black Rock" = "#BFEFFF",
                 "Footprint" = "#63B8FF",
                 "Lost" = "#0e4d92",
                 "Soldier" = "#9696CD", 
                 "Skelton" = "#5D478B", 
                 "Bullfrog" = "#FFBBFF",
                 "Middle Gaylor"= "#CD96CD")



lake_colors_2 <- c(
        "Crescent" = "#EE6363","Canyon" = "#b9ceac", 
        "Soldier" = "#9696CD", "Eyrie" = "darkolivegreen3",
        "Skelton" = "#5D478B", "Lightning" = "darkolivegreen",
        "Louise" = "#FFA07A","Scott" = "#008080",
        "Monogram" = "darkgoldenrod1","Black Rock" = "#BFEFFF",
        "Bullfrog" = "#FFBBFF", "Footprint" = "#63B8FF",
        "Middle Gaylor"= "#CD96CD","Lost" = "#0e4d92")


lake_colors_3 <- c("Crescent" = "#EE6363", 
                 "Louise" = "#FFA07A",
                 "Monogram" = "darkgoldenrod1",
                 "Soldier" = "#9696CD", 
                 "Skelton" = "#5D478B", 
                 "Bullfrog" = "#FFBBFF",
                 "Middle Gaylor"= "#CD96CD",
                 "Scott" = "#008080",
                 "Black Rock" = "#BFEFFF",
                 "Footprint" = "#63B8FF",
                 "Lost" = "#0e4d92",
                 "Canyon" = "#b9ceac", 
                 "Eyrie" = "darkolivegreen3",
                 "Lightning" = "darkolivegreen")

lake_colors_RA <- c(
        "Crescent - WA" = "#EE6363","Canyon - WY" = "#b9ceac", 
        "Soldier - CA" = "#9696CD", "Eyrie - WY" = "darkolivegreen3",
        "Skelton - CA" = "#5D478B", "Lightning - WY" = "darkolivegreen",
        "Louise - WA" = "#FFA07A","Scott - WY" = "#008080",
        "Monogram - WA" = "darkgoldenrod1","Black Rock - WY" = "#BFEFFF",
        "Bullfrog - CA" = "#FFBBFF", "Footprint - WY" = "#63B8FF",
        "Middle Gaylor - CA"= "#CD96CD","Lost - WY" = "#0e4d92")



source("1_LoadData/1_CreatePhyloseq_ZOTUexact_TAX80.R")
rm(ps_V7_norm) # only working with 18S V9 data - remove 18S V7
```


# 1. Compile sample metadata and run 210Pb modelling
```{r}
###############################################
# 1. Compile sample metadata                  #
###############################################

# biogenic silica and C-H measurements

# here I am reading in the sample list to help create unique biogenic silica error and C-H error measurements per lake. 
sample_list <- read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/Core and sample information/Master/2024-10-10_MASTER_sample_id_list.csv") 
bisi<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/Biogenic silica/results/MASTER_BiogenicSilica_FTIR_measurements.csv", header = T) %>% left_join(.,sample_list, by=join_by(sample_id)) %>% select(sample_id, replicate, FTIR_measurement, FTIR_value, lake_name) 

bisi <- bisi %>%
        group_by(sample_id) %>%
        filter(all(c("R2", "R3") %in% replicate)) %>%
        ungroup() %>%
        group_by(sample_id, lake_name, FTIR_measurement) %>%
        summarize(
                range_FTIR_value = max(FTIR_value) - min(FTIR_value),
                .groups = 'drop' ) %>%
        group_by(lake_name, FTIR_measurement) %>%
        summarize(
                mean_range_FTIR_value = mean(range_FTIR_value),
                max_range_FTIR_value = max(range_FTIR_value),
                .groups = 'drop' ) %>%
        # merge summary back into data
        left_join(bisi,., by=join_by(lake_name, FTIR_measurement)) %>% 
        # get the average for each sample and measurement for the replicates
        group_by(sample_id,FTIR_measurement) %>% mutate(mean_FTIR_value=mean(FTIR_value)) %>% ungroup() %>% select(-c(FTIR_value, replicate)) %>% distinct(.) %>% left_join(.,sample_list, by=join_by(sample_id, lake_name)) %>% select(-c(lake_name,full_sample_code,lake_code,mountain_code,core,drive,top_cm,bottom_cm,mid_cm,rep_or_note)) %>%
  pivot_wider(
    names_from = FTIR_measurement, 
    values_from = c(mean_range_FTIR_value, max_range_FTIR_value, mean_FTIR_value),
    names_sep = "_"
  ) %>%  rename_with(~ gsub("FTIR_value_", "", .)) %>% rename_with(~ gsub("BSi", "BiSi", .))


table(bisi$sample_id%in%sample_list$sample_id) # all T
metadata<-left_join(sample_list,bisi, join_by(sample_id)); rm(sample_list); rm(bisi)

# 210Pb data
pb<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/210Pb dating/210lead results/MASTER_2024-09-24_210Pb_2020_2021_cores.csv", header=T)
table(pb$sample_id%in%metadata$sample_id) # all T
metadata<-left_join(metadata,pb, join_by(sample_id)); rm(pb)

# stable isotope data

iso<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/Stable isotopes/SIF_results/MASTER_stable_isotopes_2020_2021_cores.csv") 
table(iso$sample_id%in%metadata$sample_id) # all T
metadata<-left_join(metadata,iso, join_by(sample_id)); rm(iso)


# LOI data
loi<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/Subsampling and LOI/MASTER_loss_on_ignition_2015_2019-2021_cores.csv") %>% filter(mountain_lake_code%in%c("SNOW20_LOST20_1A_1G", "SNOW20_SCOT20_1A_1G","WIND20_BLRO20_1A_1G", "WIND20_CANY20_1A_1G" ,"WIND20_EYRI20_1A_1G", "WIND20_FOOT20_1A_1G","WIND20_LIGH20_1A_1G", "MORA21_CRES21_1A_1G", "MORA21_LOUI21_1A_1G",
"NOCA21_MONO21_1A_1G", "SEKI21_BULL21_2A_1G", "YOSE21_MIGA21_1A_1G", "YOSE21_SKEL21_1A_1G", "YOSE21_SOLD21_1A_1G")) %>% select(-c(top_cm,bottom_cm,full_sample_code, year_cored))
table(loi$sample_id%in%metadata$sample_id) # all T
setdiff(loi$sample_id, metadata$sample_id) # these two samples were combined into SOLD21_0to1 so OK!
metadata<-left_join(metadata,loi, join_by(sample_id)); rm(loi)

# lake data
lake<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/Core and sample information/Master/2024-10-10_MASTER_lake_data.csv")
table(lake$lake_name%in%metadata$lake_name) # all T
metadata<-left_join(metadata,lake, join_by(lake_name)); rm(lake)

# remove lakes and samples not included in this study
metadata<-metadata %>% filter(!lake_name %in% c("Green Park Lake","Solitude", "Delta", "Lake of the Crags")) %>% filter(!sample_id%in% c("SOLD21_0to1","SOLD21_1.5"))


# - 660 samples from 14 lakes (removed two samples from Soldier lake that were too watery to do any analyses on)
# - Only 659 of these samples had DNA run on them (SOLD21_22.5 was not sequenced)

###############################################
# 2. Model 210Pb dating                       #
###############################################

# Here I am:
# 1. using Loess line to interpolate samples that did not have 210Pb measured but were within the range of 210Pb dating measurements
# 2. extrapolating past the range of 210Pb dating using the dry mass accumulation rate (DMAR)
# 3. creating three final columns that are a combination of the measured 210Pb dates, the interpolated dates, and extrapolated dates. 

# indicate if 210Pb was measured for the sample
pb <- metadata %>% mutate(lead210_measured=ifelse(is.na(lead210_measured)==T,"n","y"))

# remove the bottom Soldier sample dating back around 1850 because the error is ~350 years and is messing up extrapolation. 
pb<-pb %>%  mutate(across(c(cum_dry_mass_g_cm2, unsup_210Pb_pCi_g, error_of_unsup_Pb_sd,age_base_of_interval_yr,error_of_age_sd,date_mid_AD,date_base_AD,DMAR_g_cm2_yr,error_DMAR_sd),
                ~ ifelse(sample_id == "SOLD21_17", NA, .)))

# calculate density and rho for using with dry mass accumulation rate (DMAR)
pb <- pb %>%
        mutate(dry_perc=100-water_perc,
               wet_density_g_cm3=wet_wt_g/volume_cm3,
               all_rho_g_cm3=round(dry_perc/(dry_perc/2.4+water_perc),digits=4))
# only wet density for Wind River and Snowy cores (maybe a few CA cores)

# indicate if the part of the core is exact measurement, interpolated, or extrapolated
# first calculate the deepest 210Pb measurement
max_bottom_cm <- pb %>%
  group_by(lake_name) %>%
  filter(is.na(date_mid_AD) == F) %>%
  summarize(max_bottom_cm_210Pb_dated = max(bottom_cm))%>% ungroup()

# then calculate the shallowest 210Pb measurement
min_bottom_cm <- pb %>%
  group_by(lake_name) %>%
  filter(is.na(date_mid_AD) == F) %>%
  summarize(min_bottom_cm_210Pb_dated = min(bottom_cm))%>% ungroup()


# merge with main data frame
pb<- left_join(pb,max_bottom_cm, by=join_by(lake_name)); rm(max_bottom_cm) # max
pb<- left_join(pb,min_bottom_cm, by=join_by(lake_name)); rm(min_bottom_cm) # min

pb <- pb %>% group_by(lake_name) %>%
        mutate(date_type=ifelse(bottom_cm>max_bottom_cm_210Pb_dated,"extrapolated",
                                ifelse(lead210_measured=="y","measured",
                                        ifelse(lead210_measured=="n","interpolated",NA )))) %>% ungroup()

# use Loess line to predict interpolated values (middle of sample)

interpolated_dates_mid <- pb %>%
        group_by(lake_name) %>%
        do({
        loess_fit_mean <- loess(date_mid_AD ~ mid_cm, data = .)
        loess_fit_sd <- loess(error_of_age_sd ~ mid_cm, data = .)
        new_data <- data.frame(mid_cm = seq(unique(.$min_bottom_cm_210Pb_dated)- 0.25, unique(.$max_bottom_cm_210Pb_dated) - 0.25, by = 0.5))
        new_data$interpolated_date_mid_AD <- round(predict(loess_fit_mean, newdata = new_data),digits=2)
        new_data$interpolated_error_of_age_sd <- round(predict(loess_fit_sd, newdata = new_data), digits=3)
        new_data$lake_name <- .$lake_name[1] 
        new_data
        }) %>%
        unnest(cols = c(interpolated_date_mid_AD, interpolated_error_of_age_sd, mid_cm, lake_name)) %>% ungroup()

# use Loess line to predict interpolated values (base/bottom of sample)
interpolated_dates_base <- pb  %>%
        group_by(lake_name) %>%
        do({
        loess_fit_mean <- loess(date_base_AD ~ mid_cm, data = .)
        new_data <- data.frame(mid_cm = seq(unique(.$min_bottom_cm_210Pb_dated)- 0.25, unique(.$max_bottom_cm_210Pb_dated) - 0.25, by = 0.5))
        new_data$interpolated_date_base_AD <- round(predict(loess_fit_mean, newdata = new_data),digits=2)
        new_data$lake_name <- .$lake_name[1] 
        new_data
        }) %>%
        unnest(cols = c(interpolated_date_base_AD, mid_cm, lake_name)) %>% ungroup()

# add in a column for the top sediment date (used to approximate the top of the interval for prism data)

# function to convert date to decimal year
decimal_year <- function(date) {
  year <- year(date)
  start_of_year <- ymd(paste0(year, "-01-01"))
  days_in_year <- ifelse(leap_year(date), 366, 365) # Account for leap years
  fractional_year <- as.numeric(difftime(date, start_of_year, units = "days")) / days_in_year
  year + fractional_year
} 

#make a dataframe that has the decimal year for each lake
date_cored <- pb %>%
  select(lake_name,date_cored) %>% distinct(.) %>%  mutate(decimal_year=decimal_year(dmy(date_cored))) %>% select(-date_cored)
        
# add it to the interpolated_dates_base dataframe
interpolated_dates_base <-left_join(interpolated_dates_base,date_cored, join_by(lake_name)); rm(date_cored)

interpolated_dates_base <- interpolated_dates_base %>% group_by(lake_name) %>% mutate(interpolated_date_top_AD = c(decimal_year[1],interpolated_date_base_AD[1:length(interpolated_date_base_AD)-1])) %>% select(-decimal_year)

rm(decimal_year) # remove this function

# join the two columns for the middle date and the base date
interpolated_dates<-inner_join(interpolated_dates_mid,interpolated_dates_base, by=join_by(lake_name,mid_cm)); rm(interpolated_dates_mid); rm(interpolated_dates_base)

# merge back the interpolated dates
pb <-left_join(pb,as.data.frame(interpolated_dates), by=join_by(lake_name, mid_cm)); rm(interpolated_dates)


# extrapolate using the DMAR
# calculate the average DMAR for the last three samples
average_DMAR <- pb %>%
  group_by(lake_name) %>%
  filter(is.na(DMAR_g_cm2_yr) == F) %>%
  reframe(mean_DMAR_g_cm2_yr_bottom3 = mean(tail(DMAR_g_cm2_yr, n = 3)),
        mean_error_DMAR_sd_bottom3 = mean(tail(error_DMAR_sd, n = 3)),
        mean_DMAR_g_cm2_yr_bottom3_max = mean_DMAR_g_cm2_yr_bottom3 + mean_error_DMAR_sd_bottom3,
        mean_DMAR_g_cm2_yr_bottom3_min = mean_DMAR_g_cm2_yr_bottom3 - mean_error_DMAR_sd_bottom3,
        bottom_interpolated_error= tail(interpolated_error_of_age_sd,n=1),
        bottom_measured_date_mid_AD = tail(date_mid_AD, n=1)) %>%
        mutate(mean_DMAR_g_cm2_yr_bottom3_min = ifelse(mean_DMAR_g_cm2_yr_bottom3_min<0,0.01,mean_DMAR_g_cm2_yr_bottom3_min)) 
# used error of DMAR 0.001 because range for this data is 0.00024 0.03320 and using 0 produced -Inf

# join back to the main dataframe
pb <- left_join(pb, average_DMAR, by=join_by(lake_name)); rm(average_DMAR)

# calculate the accumulation rate 
pb <- pb %>%
        mutate(thickness=bottom_cm-top_cm,
               # calculate the mean DMAR 
               accumulation_rate_cm_yr=ifelse(date_type=="extrapolated",mean_DMAR_g_cm2_yr_bottom3 /all_rho_g_cm3, NA),
               years_per_thickness=thickness/accumulation_rate_cm_yr,
               # calculate the mean error for DMAR 
               accumulation_rate_max_cm_yr=ifelse(date_type=="extrapolated",mean_DMAR_g_cm2_yr_bottom3_max /all_rho_g_cm3, NA),
               accumulation_rate_min_cm_yr=ifelse(date_type=="extrapolated",mean_DMAR_g_cm2_yr_bottom3_min /all_rho_g_cm3, NA),
               years_per_thickness_max=thickness/accumulation_rate_max_cm_yr,
               years_per_thickness_min=thickness/accumulation_rate_min_cm_yr)
        
extrapolated_dates <- pb %>% group_by(lake_name) %>% filter(date_type=="extrapolated") %>%
        mutate(cumulative_years = cumsum(years_per_thickness),
               extrapolated_date_mid_AD = round(bottom_measured_date_mid_AD - cumulative_years,digits=2),
               # using error of DMAR
               cumulative_years_max = cumsum(years_per_thickness_max),
               extrapolated_date_mid_AD_max = round(bottom_measured_date_mid_AD - cumulative_years_max,digits=2),
                cumulative_years_min = cumsum(years_per_thickness_min),
               extrapolated_date_mid_AD_min = round(bottom_measured_date_mid_AD - cumulative_years_min,digits=2))%>% 
        ungroup() %>%  select(sample_id,cumulative_years, extrapolated_date_mid_AD, cumulative_years_max, extrapolated_date_mid_AD_max,  cumulative_years_min, extrapolated_date_mid_AD_min)

# join back to the main dataframe
pb <- left_join(pb, extrapolated_dates, by=join_by(sample_id)); rm(extrapolated_dates)

# create one column for the measured, interpolated, and extrapolated dates
pb <- pb %>% 
        mutate(date_mid_AD_combo=case_when(date_type=="measured" ~ date_mid_AD,
                                           date_type=="extrapolated" ~ extrapolated_date_mid_AD,
                                           date_type=="interpolated" ~ interpolated_date_mid_AD),
               date_mid_AD_min_combo= case_when(date_type=="measured" ~ date_mid_AD - error_of_age_sd,
                                           date_type=="extrapolated" ~ extrapolated_date_mid_AD_min- bottom_interpolated_error,
                                           date_type=="interpolated" ~ interpolated_date_mid_AD - interpolated_error_of_age_sd),
               date_mid_AD_max_combo= case_when(date_type=="measured" ~ date_mid_AD + error_of_age_sd,
                                           date_type=="extrapolated" ~ extrapolated_date_mid_AD_max + bottom_interpolated_error,
                                           date_type=="interpolated" ~ interpolated_date_mid_AD + interpolated_error_of_age_sd))
pb <- as.data.frame(pb)

#########################################################################
# 3. Adding extra variables after the chronology has been incorporated  #
#########################################################################




# Add whether fish are present for each sample based on the 210Pb results
pb <- pb %>%
        arrange(lake_name,bottom_cm) %>%
        group_by(lake_name)%>%
        mutate(fish_present_sample = ifelse(first_stocked_yr>=date_mid_AD_combo | is.na(first_stocked_yr) ==T, "fishless","fish"))  %>%  
        mutate(fish_present_sample = if_else(!is.na(fish_disappear_or_eradicated) & fish_disappear_or_eradicated <= date_mid_AD_combo, "fishless", fish_present_sample)) %>% ungroup()

# convert this to a binary predictor (0/1)
pb <- pb %>% mutate(fish_present_binary=case_when(fish_present_sample =="fishless"~0, 
                                               fish_present_sample =="fish" ~ 1 ))

# add in climate data from PRISM
prism <- read.csv("2_DataAnalysis/PRISM/PRISM_ppt_tmean_stable_4km_1895_2021.csv", header = TRUE, skip = 10) %>%
mutate(Name=case_when(Name=="Middle Gaylo"~"Middle Gaylor", 
                      TRUE ~Name)) %>%
  filter(complete.cases(.)) 

# use base R for renaming columns since the dplyr rename() function keeps giving errors when has worked fine in the past. Consistent issue I keep finding.
colnames(prism)[1] <- "lake_name"
colnames(prism)[colnames(prism) == "ppt..mm."] <- "precip_ppt_mm"
colnames(prism)[colnames(prism) == "tmean..degrees.C."] <- "mean_air_temp_degC"
colnames(prism)[colnames(prism) == "Longitude"] <- "longitude_prism"
colnames(prism)[colnames(prism) == "Latitude"] <- "latitude_prism"
colnames(prism)[colnames(prism) == "Elevation..m."] <- "elevation_prism"

prism <- prism %>% mutate(lake_name = factor(lake_name))

# make a new column that uses the exact date_base_AD is present to create the top and base intervals, but if not available, use the interpolated base dates
temp <- pb %>% filter(interpolated_date_base_AD>1894) %>% 
        select(lake_name, bottom_cm,date_mid_AD, date_base_AD, interpolated_date_base_AD, interpolated_date_top_AD) %>% 
        distinct() %>% 
        mutate(prism_date_base_AD=case_when(is.na(date_base_AD)==T ~ interpolated_date_base_AD,
                                            is.na(date_base_AD)==F ~ date_base_AD)) %>% 
        group_by(lake_name) %>%
        mutate(prism_date_top_AD = c(interpolated_date_top_AD[1],prism_date_base_AD[1:length(prism_date_base_AD)-1])) %>% 
        ungroup()%>% 
        select(lake_name, bottom_cm, prism_date_base_AD,prism_date_top_AD)                                                                                                                           
# calculate the average temperature for each sediment interval
# here I am using the interpolated base date and a top interval calculated from the 210Pb (not incorporating the error because we need an estimate of the interval itself that doesn't overlap)
new_df<-data.frame()
i=1
for(i in 1:nrow(temp)){
        sub<-temp[i,]
        sub$mean_air_temp_degC_interval<-mean(prism[prism$lake_name==sub$lake_name[1] & prism$Date >= floor(sub$prism_date_base_AD) & prism$Date <= floor(sub$prism_date_top_AD), "mean_air_temp_degC"])
        new_df<-rbind(new_df,sub)
}

# join the prism data back in
pb<-left_join(pb, new_df, join_by(lake_name,bottom_cm))


# determine the mid century mean from 1951-1980
mid_cent_mean<-prism %>% filter(Date > 1950 & Date < 1981) %>% group_by(lake_name) %>% 
        summarize(mean_air_temp_1951_1980_degC=mean(mean_air_temp_degC))

# add it into the metadata and create the anomaly for the interval value
pb <- pb %>% left_join(., mid_cent_mean, join_by(lake_name)) %>% 
        mutate(temp_anomaly_mid_cent_degC=mean_air_temp_degC_interval-mean_air_temp_1951_1980_degC)


# calculate the bottom interval with prism climate data to extrapolate to past
last_anomaly_interval_temp <- pb %>%
  filter(is.na(temp_anomaly_mid_cent_degC)==F) %>%
  group_by(lake_name) %>%
  filter(date_mid_AD_combo == min(date_mid_AD_combo)) %>%
  summarize(temp_anomaly_mid_cent_degC_start = temp_anomaly_mid_cent_degC[1], .groups = "drop") %>% ungroup


# If the sediment interval is prior to observation (prior to 1895), use the last anomaly interval "observation"
pb <- pb %>% left_join(.,last_anomaly_interval_temp, join_by(lake_name)) %>% 
        mutate(mean_air_temp_degC_anomaly_combined=case_when(is.na(temp_anomaly_mid_cent_degC)==F ~ temp_anomaly_mid_cent_degC, 
                                                              is.na(temp_anomaly_mid_cent_degC)==T ~ temp_anomaly_mid_cent_degC_start)) %>%
        mutate(mean_air_temp_degC_anomaly_extended=case_when(is.na(temp_anomaly_mid_cent_degC)==F ~ NA, 
                                                              is.na(temp_anomaly_mid_cent_degC)==T ~ temp_anomaly_mid_cent_degC_start))


rm(temp); rm(new_df); rm(prism); rm(sub); rm(i); rm(last_anomaly_interval_temp); rm(mid_cent_mean) 


### Updating the nitrogen isotope values ###
# 1. For CN and CNS, subtract the mean difference of the two runs from CNS run (d15N_CNS_adj)
# 2. Calculate the 1800-1850 mean (mean_d15N_1800_1850)
# 3. Create an anomaly value (d15N_anomaly_mean_1800_1850)

# subset lakes that have CNS measurements, find the mean difference between the two datasets for each lake, subtract it from the CNS measurement, join back into metadata
pb <- left_join(pb,

        pb %>% filter(lake_name %in%
        (pb %>% filter(isotope_run == "CNS") %>% pull(lake_name) %>% unique())) %>%
        select(sample_id,lake_name, isotope_run, d15N) %>% 
        filter(complete.cases(.)) %>% 
        group_by(lake_name) %>% 
        mutate(diff=mean(d15N[isotope_run=="CNS"])-mean(d15N[isotope_run=="CN"])) %>% 
        mutate(d15N_CNS_adj=case_when(isotope_run=="CNS"~ d15N - diff,
                                  isotope_run=="CN" ~ d15N)) %>% 
        ungroup() %>% select(sample_id,d15N_CNS_adj), 
        
        join_by(sample_id)) %>% 
        
        # for lakes with CNS run, make the d15N value the d15N_CNS_adj
        mutate(d15N_CNS_adj=case_when(is.na(d15N_CNS_adj)==T ~ d15N ,
                                  is.na(d15N_CNS_adj)==F ~ d15N_CNS_adj))


# determine the mean from 1800-1850, add it to the metadata spreadsheet, and create the anomaly for d15N from the mean
pb <-left_join(pb, 

        pb %>% filter(date_mid_AD_combo >= 1800 & date_mid_AD_combo < 1850) %>% 
        select(lake_name, d15N_CNS_adj) %>% 
        group_by(lake_name) %>% 
        mutate(mean_d15N_1800_1850 = mean(d15N_CNS_adj, na.rm=T)) %>% 
        select(lake_name, mean_d15N_1800_1850) %>% distinct()

        , join_by(lake_name)) %>% 
mutate(d15N_anomaly_mean_1800_1850 = d15N_CNS_adj - mean_d15N_1800_1850)

# calculate the difference from starting value for d15N using the CNS adjusted value
d15N_start_summary <- pb %>% group_by(lake_name) %>%
        filter(is.na(d15N_CNS_adj)==F) %>%
        summarize(d15N_CNS_adj_start = d15N_CNS_adj[which.max(bottom_cm)]) %>% ungroup()

# add back in to metadata
pb <- left_join(pb,d15N_start_summary, join_by(lake_name)) %>%
        mutate(d15N_CNS_adj_diff_from_start=d15N_CNS_adj-d15N_CNS_adj_start); rm(d15N_start_summary)


# change lake_name to include the state
pb <- pb %>% mutate(state_short=case_when(state=="Wyoming"~"WY", 
                                            state=="California"~"CA",
                                            state=="Washington"~"WA"),
                      lake_name_state=paste(lake_name,state_short, sep=" - "))

pb <- pb %>% arrange(lake_name, bottom_cm)
pb <- as.data.frame(pb)
write.csv(pb,paste0(Sys.Date(),"_sample_data_dates.csv"))
rm(pb);rm(metadata)
```

1. For CN and CNS, subtract the difference from C
2. Calculate the 1800-1850 mean
3. Create an anomaly value
```{r}
# subset lakes that have CNS measurements, find the mean difference between the two datasets for each lake, subtract it from the CNS measurement, join back into metadata
pb <- left_join(pb,

        pb %>% filter(lake_name %in%
        (pb %>% filter(isotope_run == "CNS") %>% pull(lake_name) %>% unique())) %>%
        select(sample_id,lake_name, isotope_run, d15N) %>% 
        filter(complete.cases(.)) %>% 
        group_by(lake_name) %>% 
        mutate(diff=mean(d15N[isotope_run=="CNS"])-mean(d15N[isotope_run=="CN"])) %>% 
        mutate(d15N_CNS_adj=case_when(isotope_run=="CNS"~ d15N - diff,
                                  isotope_run=="CN" ~ d15N)) %>% 
        ungroup() %>% select(sample_id,d15N_CNS_adj), 
        
        join_by(sample_id)) %>% 
        
        # for lakes with CNS run, make the d15N value the d15N_CNS_adj
        mutate(d15N_CNS_adj=case_when(is.na(d15N_CNS_adj)==T ~ d15N ,
                                  is.na(d15N_CNS_adj)==F ~ d15N_CNS_adj))



# determine the mean from 1800-1850, add it to the metadata spreadsheet, and create the anomaly for d15N from the mean
pb <-left_join(pb, 

        pb %>% filter(date_mid_AD_combo >= 1800 & date_mid_AD_combo < 1850) %>% 
        select(lake_name, d15N_CNS_adj) %>% 
        group_by(lake_name) %>% 
        mutate(mean_d15N_1800_1850 = mean(d15N_CNS_adj, na.rm=T)) %>% 
        select(lake_name, mean_d15N_1800_1850) %>% distinct()

        , join_by(lake_name)) %>% 
mutate(d15N_anomaly_mean_1800_1850 = d15N_CNS_adj - mean_d15N_1800_1850)


```


# 2. Manuscript values

## - DNA reads 
```{r}
esv_table<-read.delim("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/ZooplanktonSedDNA/1_RawSeqProcessing/output/V9_ZOTU_table_exact", header = TRUE, stringsAsFactors = FALSE, quote = "", sep = "\t")

# change the OTU name to be a row name
rownames(esv_table)<-esv_table$X.OTU.ID
esv_table$X.OTU.ID<-NULL

# convert sample names
names(esv_table)<-gsub("botcm","_",names(esv_table))
names(esv_table)<-gsub("point",".",names(esv_table))
names(esv_table)<-gsub("_Rep","",names(esv_table))
names(esv_table)<-gsub("_rep","",names(esv_table))

# pick the MIGA21_0.5_rewash sample going forward
esv_table <- esv_table %>% select(-MIGA21_0.5)
names(esv_table)<-gsub("MIGA21_0.5rewash","MIGA21_0.5",names(esv_table)) # MIGA21_0.5 is the only sample that is truly duplicated, (MIGA21_0.5 and MIGA21_0.5_rewash). Kept the MIGA21_0.5_rewash.

# rename CRES20_8.5 to CRES21_8.5
names(esv_table)<-gsub("CRES20_8.5","CRES21_8.5",names(esv_table)) 



# subset blanks
blanks<- c()
for (i in 1:ncol(esv_table)){
       if(length(grep("ExtractionBlank", colnames(esv_table)[i], value = T)) > 0){
                blanks<- append(blanks, i)
        }}
rm(i)

esv_noblanks<-esv_table[,-blanks]
rm(blanks)

metadata<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2025-01-16_sample_data_dates.csv", header=T, row.names=1)

table(metadata$sample_id %in% names(esv_noblanks))
setdiff(metadata$sample_id, names(esv_noblanks))
# no "SOLD21_22.5" sample

esv_tab <- esv_noblanks[, colnames(esv_noblanks) %in% metadata$sample_id]

# total reads and samples
paste(Sys.Date(),sum(colSums(esv_tab)), sep=": ")

# average reads per sample
paste(Sys.Date(),round(sum(colSums(esv_tab))/ncol(esv_tab), digits=2), sep=": ")

ncol(esv_tab)
# Number of samples: 659 that have DNA to start, but we did collected 660 samples total (that have 210pb dating, nitrogen values)
#[1] "2025-01-22: 103,077,659"
#[1] "2025-01-22: 156415.26"


```

Final reads V9
```{r}
sum(colSums(otu_table(ps_V9_norm)))
nrow(otu_table(ps_V9_norm))


# 5971420 - number of total reads after normalizing 
# 12838 - number of ESVs
```

## - 210Pb dating
1. calculate bottom ages constrained by 210 Pb dating 
2. extrapolated ages
3. calculate accumulation rates for constrained dates
```{r}
# function to convert date to decimal year
decimal_year <- function(date) {
  year <- year(date)
  start_of_year <- ymd(paste0(year, "-01-01"))
  days_in_year <- ifelse(leap_year(date), 366, 365) # Account for leap years
  fractional_year <- as.numeric(difftime(date, start_of_year, units = "days")) / days_in_year
  year + fractional_year 
} 

# bottom ages constrained by 210Pb dating, error for those dates and accumulation rates
summary<-metadata %>% filter(!date_type=="extrapolated") %>%
  group_by(lake_name) %>%
  filter(bottom_cm == max(bottom_cm)) %>%
  ungroup() %>%  mutate(decimal_year=decimal_year(dmy(date_cored))) %>% 
        select(bottom_measured_date_mid_AD, bottom_cm, lake_name, decimal_year, error_of_age_sd) %>% 
        mutate(years_measured_210Pb=decimal_year - bottom_measured_date_mid_AD,
               accum_rate=bottom_cm/years_measured_210Pb) %>% arrange(bottom_measured_date_mid_AD)

rm(decimal_year)
print(summary)

#    bottom_measured_date_…¹ bottom_cm lake_name decimal_year error_of_age_sd years_measured_210Pb accum_rate
#                      <dbl>     <dbl> <chr>            <dbl>           <dbl>                <dbl>      <dbl>
#  1                   1814.      18.5 Middle G…        2022.            28.1                 208.     0.0890
#  2                   1824.      11.5 Scott            2021.            21.3                 196.     0.0586
#  3                   1835.      14   Crescent         2022.            19.6                 187.     0.0749
#  4                   1836.      13.5 Monogram         2022.            38.7                 185.     0.0728
#  5                   1839.       8   Canyon           2021.            19.2                 182.     0.0440
#  6                   1846.       9   Footprint        2021.            24.2                 174.     0.0517
#  7                   1849.      19.5 Bullfrog         2022.            35.9                 172.     0.113 
#  8                   1855.      20   Lost             2021.            18.3                 166.     0.121 
#  9                   1869.      15   Louise           2022.            36.3                 152.     0.0984
# 10                   1873.      10.5 Black Ro…        2021.            14.6                 147.     0.0712
# 11                   1884.       6   Skelton          2022.            26.4                 137.     0.0437
# 12                   1887.      12   Eyrie            2021.            75.8                 133.     0.0901
# 13                   1887.       5   Lightning        2021.            16.1                 133.     0.0376
# 14                   1920.      14   Soldier          2022.            32.8                 101.     0.138 


# what is the range of oldest ages from 210Pb dating 
round(range(summary$bottom_measured_date_mid_AD),digits=1)
#1] 1813.8 1920.4
#[1] 1813 (middle gaylor) 1920 (soldier)

# what about soldier... ya that is right..
metadata %>% filter(lake_name=="Soldier") %>% select(bottom_cm, date_mid_AD)

# average of oldest ages
round(mean(summary$bottom_measured_date_mid_AD), digits=1)
round(mean(summary$error_of_age_sd), digits=1)
hist(summary$bottom_measured_date_mid_AD, breaks=10)

# what is the range of accumulation rates
round(range(summary$accum_rate), digits=3)

# average accumulation rate
round(mean(summary$accum_rate), digits=3)

# bottom extrapolated ages and errors 
summary<-metadata %>% filter(date_type=="extrapolated") %>%
  group_by(lake_name) %>%
  filter(bottom_cm == max(bottom_cm)) %>%
  ungroup() %>%  mutate(decimal_year=decimal_year(dmy(date_cored))) %>% 
        select(date_mid_AD_combo,date_mid_AD_min_combo, date_mid_AD_max_combo, lake_name) %>% arrange(date_mid_AD_combo)

print(summary)

#    date_mid_AD_combo date_mid_AD_min_combo date_mid_AD_max_combo lake_name    
#                <dbl>                 <dbl>                 <dbl> <chr>        
#  1             1273.                 -975.                 1560. Monogram     
#  2             1322.                 1033.                 1478. Footprint    
#  3             1372.                  817.                 1570. Skelton      
#  4             1388.                 1067.                 1535. Canyon       
#  5             1568.                 1445.                 1647. Lightning    
#  6             1614.                 1413.                 1702. Middle Gaylor
#  7             1644.                 1482.                 1723. Lost         
#  8             1688.                 1584.                 1746. Scott        
#  9             1690.                 1340.                 1793. Louise       
# 10             1708.                 1625.                 1760. Black Rock   
# 11             1712.                 1411.                 1883. Eyrie        
# 12             1760.                 1681.                 1815. Bullfrog     
# 13             1772.                 1733.                 1803. Crescent     
# 14             1822.                 1650.                 1891. Soldier 

floor(range(summary$date_mid_AD_combo))
#[1] 1273 1822

mean(summary$date_mid_AD_combo)
#  1595.228
```

## - temperature
```{r}
# add in temperature breakpoints - when do most lakes start to have increasing air temperatures
temp_break<-read.csv("2_DataAnalysis/temperature_anomaly_breakpoints.csv", header=T,row.names=1)
round(mean(temp_break$temperature_breakpoint_date),digits=1)
round(sd(temp_break$temperature_breakpoint_date),digits=1)
hist(temp_break$temperature_breakpoint_date, breaks=10)

# what is the average and range in magnitude of the temperature change?
# what is the average increase in temperature
metadata %>% select(mean_air_temp_degC_anomaly_combined, lake_name, date_mid_AD_combo) %>% group_by(lake_name) %>% summarize(max_temp_increase=max(mean_air_temp_degC_anomaly_combined)) %>% pull(max_temp_increase) %>% mean(.) %>% round(.,digits=2)
# sd on avg. increase in temp
metadata %>% select(mean_air_temp_degC_anomaly_combined, lake_name) %>% group_by(lake_name) %>% summarize(max_temp_increase=max(mean_air_temp_degC_anomaly_combined)) %>% pull(max_temp_increase) %>% sd(.) %>% round(.,digits=2)
# when did this average increase occur?
metadata %>%
  select(mean_air_temp_degC_anomaly_combined, lake_name, date_mid_AD_combo) %>%
  group_by(lake_name) %>%
  slice_max(mean_air_temp_degC_anomaly_combined, n = 1, with_ties = FALSE) %>% pull(date_mid_AD_combo) %>% mean(.) %>% round(.,digits=1)
# sd on when increase occurred
metadata %>%
  select(mean_air_temp_degC_anomaly_combined, lake_name, date_mid_AD_combo) %>%
  group_by(lake_name) %>%
  slice_max(mean_air_temp_degC_anomaly_combined, n = 1, with_ties = FALSE) %>% pull(date_mid_AD_combo) %>% sd(.) %>% round(.,digits=1)

# How much does WA increase in temperature? 
metadata %>%
  select(mean_air_temp_degC_anomaly_combined, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_max(mean_air_temp_degC_anomaly_combined, n = 1, with_ties = FALSE) %>% filter(state=="Washington") %>% pull(mean_air_temp_degC_anomaly_combined) %>% mean(.) %>% round(.,digits=2)

metadata %>%
  select(mean_air_temp_degC_anomaly_combined, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_max(mean_air_temp_degC_anomaly_combined, n = 1, with_ties = FALSE) %>% filter(state=="Washington") %>% pull(mean_air_temp_degC_anomaly_combined) %>% sd(.) %>% round(.,digits=2)



# How much does WY increase in temperature? 
metadata %>%
  select(mean_air_temp_degC_anomaly_combined, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_max(mean_air_temp_degC_anomaly_combined, n = 1, with_ties = FALSE) %>% filter(state=="Wyoming") %>% pull(mean_air_temp_degC_anomaly_combined) %>% mean(.) %>% round(.,digits=2)

metadata %>%
  select(mean_air_temp_degC_anomaly_combined, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_max(mean_air_temp_degC_anomaly_combined, n = 1, with_ties = FALSE) %>% filter(state=="Wyoming") %>% pull(mean_air_temp_degC_anomaly_combined) %>% sd(.) %>% round(.,digits=2)


# How much does CA increase in temperature? 
metadata %>%
  select(mean_air_temp_degC_anomaly_combined, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_max(mean_air_temp_degC_anomaly_combined, n = 1, with_ties = FALSE) %>% filter(state=="California") %>% pull(mean_air_temp_degC_anomaly_combined) %>% mean(.) %>% round(.,digits=2)

metadata %>%
  select(mean_air_temp_degC_anomaly_combined, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_max(mean_air_temp_degC_anomaly_combined, n = 1, with_ties = FALSE) %>% filter(state=="California") %>% pull(mean_air_temp_degC_anomaly_combined) %>% sd(.) %>% round(.,digits=2)



# when does WA, CA, and WY start to increase?  - didn't use this
# temp_break %>% filter(lake_name%in%c("Crescent", "Louise"," Monogram")) %>% pull(temperature_breakpoint_date) %>% mean(.)
# temp_break %>% filter(lake_name%in%c("Crescent", "Louise"," Monogram")) %>% pull(temperature_breakpoint_date) %>% sd(.)
# 
# temp_break %>% filter(lake_name%in%c("Soldier", "Skelton","Middle Gaylor","Bullfrog")) %>% pull(temperature_breakpoint_date) %>% mean(.)
# temp_break %>% filter(lake_name%in%c("Soldier", "Skelton","Middle Gaylor","Bullfrog")) %>% pull(temperature_breakpoint_date) %>% sd(.)
# 
# temp_break %>% filter(lake_name%in%c("Eyrie","Lightning","Canyon","Black Rock","Scott","Footprint","Lost")) %>% pull(temperature_breakpoint_date) %>% mean(.)
# temp_break %>% filter(lake_name%in%c("Eyrie","Lightning","Canyon","Black Rock","Scott","Footprint","Lost")) %>% pull(temperature_breakpoint_date) %>% sd(.)
```

## - nitrogen isotope values
```{r}
# when do most lakes start increasing in N deposition
n_break<-read.csv("2_DataAnalysis/d15N_breakpoints.csv", header=T,row.names=1)
round(mean(n_break$d15N_breakpoint_date),digits=1)
round(sd(n_break$d15N_breakpoint_date),digits=1)
hist(n_break$d15N_breakpoint_date, breaks=10)

# what is the range in magnitude of the n dep change?

# when does WA, CA, and WY start to increase? 
n_break %>% filter(lake_name%in%c("Crescent", "Louise"," Monogram")) %>% pull(d15N_breakpoint_date) %>% mean(.)%>% round(.,digits=1)
n_break %>% filter(lake_name%in%c("Crescent", "Louise"," Monogram")) %>% pull(d15N_breakpoint_date) %>% sd(.)%>% round(.,digits=1)

n_break %>% filter(lake_name%in%c("Soldier", "Skelton","Middle Gaylor","Bullfrog")) %>% pull(d15N_breakpoint_date) %>% mean(.)%>% round(.,digits=1)
n_break %>% filter(lake_name%in%c("Soldier", "Skelton","Middle Gaylor","Bullfrog")) %>% pull(d15N_breakpoint_date) %>% sd(.)%>% round(.,digits=1)

n_break %>% filter(lake_name%in%c("Eyrie","Lightning","Canyon","Black Rock","Scott","Footprint","Lost")) %>% pull(d15N_breakpoint_date) %>% mean(.) %>% round(.,digits=1)
n_break %>% filter(lake_name%in%c("Eyrie","Lightning","Canyon","Black Rock","Scott","Footprint","Lost")) %>% pull(d15N_breakpoint_date) %>% sd(.) %>% round(.,digits=1)



# How much does N isotopic values decline from anomaly in WA and when? 
metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="Washington") %>% pull(d15N_anomaly_mean_1800_1850) %>% mean(.) %>% round(.,digits=2)

metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="Washington") %>% pull(d15N_anomaly_mean_1800_1850) %>% sd(.) %>% round(.,digits=2)

metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="Washington") %>% pull(date_mid_AD_combo) %>% mean(.) %>% round(.,digits=1)

metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="Washington") %>% pull(date_mid_AD_combo) %>% sd(.) %>% round(.,digits=1)


# How much does N isotopic values decline from anomaly in WY? 
metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="Wyoming") %>% pull(d15N_anomaly_mean_1800_1850) %>% mean(.) %>% round(.,digits=2)

metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="Wyoming") %>% pull(d15N_anomaly_mean_1800_1850) %>% sd(.) %>% round(.,digits=2)

metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="Wyoming") %>% pull(date_mid_AD_combo) %>% mean(.) %>% round(.,digits=1)

metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="Wyoming") %>% pull(date_mid_AD_combo) %>% sd(.) %>% round(.,digits=1)


# How much does N isotopic values decline from anomaly in CA? 
metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="California") %>% pull(d15N_anomaly_mean_1800_1850) %>% mean(.) %>% round(.,digits=2)

metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="California") %>% pull(d15N_anomaly_mean_1800_1850) %>% sd(.) %>% round(.,digits=2)

metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="California") %>% pull(date_mid_AD_combo) %>% mean(.) %>% round(.,digits=1)

metadata %>%
  select(d15N_anomaly_mean_1800_1850, lake_name, date_mid_AD_combo, state) %>%
  group_by(lake_name) %>%
  slice_min(d15N_anomaly_mean_1800_1850, n = 1, with_ties = FALSE) %>% filter(state=="California") %>% pull(date_mid_AD_combo) %>% sd(.) %>% round(.,digits=1)


# Modern NADP values
# mean values for each state
read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/2025-02-04_NADP_mean_N_deposition.csv", header=T, row.names=1) %>% group_by(state) %>%
        summarize(mean_n_deposition_state=mean(mean_n_dep_kgperha))
#  state mean_n_deposition_state
# 1 CA                       5.50
# 2 WA                       3.32
# 3 WY                       4.43

read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/2025-02-04_NADP_mean_N_deposition.csv", header=T, row.names=1) %>% group_by(state) %>%
        summarize(sd_n_deposition_state=sd(mean_n_dep_kgperha))

#   state sd_n_deposition_state
# 1 CA                   1.06  
# 2 WA                   0.124 
# 3 WY                   0.0310

```



# 3. Plot 210Pb dates
```{r}
pb <- read.csv(list.files(pattern = "*_sample_data_dates.csv", full.names = TRUE), row.names = 1, header = TRUE)


lake_colors <- c("Crescent" = "#EE6363", 
                 "Louise" = "#FFA07A",
                 "Monogram" = "darkgoldenrod1",
                 "Soldier" = "#9696CD", 
                 "Skelton" = "#5D478B", 
                 "Bullfrog" = "#FFBBFF",
                 "Middle Gaylor"= "#CD96CD",
                 "Canyon" = "#b9ceac", 
                 "Eyrie" = "darkolivegreen3",
                 "Lightning" = "darkolivegreen",
                 "Scott" = "#008080",
                 "Black Rock" = "#BFEFFF",
                 "Footprint" = "#63B8FF",
                 "Lost" = "#0e4d92")


lk <- pb %>%
  mutate(lake_name = factor(lake_name, levels = names(lake_colors))) %>%
  arrange(lake_name, mid_cm) 

# make dataframes of polygons
poly <- data.frame()
for (lake in unique(lk$lake_name)) {
  lk_sub <- lk %>% filter(lake_name == lake)
  poly <- rbind(poly, data.frame(
    x = c(rev(lk_sub$date_mid_AD_min_combo), lk_sub$date_mid_AD_max_combo),
    y = c(rev(lk_sub$mid_cm), lk_sub$mid_cm),
    lake_name = lake
  ))
}
poly <- poly %>% filter(!(lake_name == "Soldier" & y %in% c(1.25, 0.5))) # remove top Soldier samples without data


poly$lake_name <- factor(poly$lake_name, levels = names(lake_colors))

ggplot() +
 geom_polygon(data = poly, aes(x = x, y = y, fill = lake_name), alpha = 0.5)+
  geom_line(data = lk, aes(x = date_mid_AD_combo, y = mid_cm, color = lake_name), linewidth = 1.5) +
  geom_point(data = filter(lk, date_type == "measured"), aes(x = date_mid_AD_combo, y = mid_cm), 
             color = "black", size = 2) +
  facet_wrap2(
    ~ lake_name, ncol = 7, strip.position = "top",
    strip = strip_themed(
      background_x = elem_list_rect(fill = lake_colors),
      text_x = elem_list_text(color = ifelse(unique(lk$lake_name)%in% c("Lightning","Lost","Scott","Skelton"), "white", "black"))
    )
  )+
  labs(x = "Date (Common Era)", y = "Depth (cm)")+
 scale_y_reverse(limits = c(30, 0), breaks = seq(0, 30, 5)) +
 custom_theme()+
scale_color_manual(values = lake_colors) +
  scale_fill_manual(values = lake_colors) +
          theme(panel.grid.minor = element_blank(),
                panel.grid.major = element_blank(),
        strip.text.x = element_text(size = 12),
        axis.text.x = element_text(angle = 60, vjust = 1, hjust = 1, color = "black", size = 12),
        axis.text.y = element_text(color = "black", size = 12),
        axis.title = element_text(size = 12),
        legend.position = "none") +
         coord_cartesian(xlim = c(1000, 2022)) +
        geom_vline(data=lk[,names(lk) %in%c("lake_name","first_stocked_yr")] %>% unique(.) %>%  filter(complete.cases(.)) %>% filter(!lake_name=="Soldier"), aes(xintercept=first_stocked_yr), color="black",linewidth=0.75) +
        geom_vline(data=lk[,names(lk) %in%c("lake_name","fish_disappear_or_eradicated")] %>% unique(.) %>%  filter(complete.cases(.)) %>% filter(lake_name=="Skelton"), aes(xintercept=fish_disappear_or_eradicated), color="gray",linewidth=0.75)+
        geom_vline(data=lk[,names(lk) %in%c("lake_name","first_stocked_yr")] %>% unique(.) %>%  filter(complete.cases(.)) %>% filter(lake_name=="Soldier"), aes(xintercept=first_stocked_yr), color="black", linetype = "dashed",linewidth=0.75)

ggsave("3_Figures/FigX_210Pb_dates.png",height=5, width=14, units="in")

```
Notes: min(poly$x)  -975.239, its monogram because it is so deep (38 cm), so cut off here at 30 cm while still reasonable

# 4. Temperature histories

For plotting/modeling: 
- temp_anomaly_mid_cent_degC is just the anomaly temperatures from mid century mean from the interval to be plotted overtop actual prism data
- mean_air_temp_degC_anomaly_extended is just the projected last value that should be hashed
- mean_air_temp_degC_anomaly_combined is the entire record with the last value included with the anomalies (for modelling)
- when I go to plot I can overlay the PRISM data on to the plot without having to merge with the sediment dates used in the metadata



breakpoint analysis for anomaly time series 
```{r}
meta <- metadata %>% filter(is.na(temp_anomaly_mid_cent_degC)==F) %>% arrange(lake_name, desc(bottom_cm))

breakpoint_summary<-data.frame(lake_name=NULL,breakpoint_1=NULL, breakpoint_2=NULL)
for(i in 1:14){
sub<-meta[meta$lake_name==unique(meta$lake_name)[i],names(meta)%in%c("sample_id","temp_anomaly_mid_cent_degC")]
sub<-ts(sub$temp_anomaly_mid_cent_degC, start=1,end=nrow(sub), frequency = 1)

## estimate breakpoints
bp.ri <- breakpoints(sub ~ 1, h = 3)
#plot(bp.ri)
sum<-summary(bp.ri)
one<-sum$breakpoints[1,]
#two<-sum$breakpoints[2,]

## fit segmented model with two breaks from minimized BIC
fac.ri <- breakfactor(bp.ri, breaks = 1, label = "seg")
fm.ri <- lm(sub ~ 0 + fac.ri)
#summary(fm.ri)

## Visualization
plot(sub, main=unique(meta$lake_name)[i])
lines(as.vector(time(sub)), fitted(fm.ri), col = 4)

breakpoint_summary<-rbind(breakpoint_summary, data.frame(lake_name=unique(meta$lake_name)[i],breakpoint_1=one[is.na(one)==F]))
}


print(breakpoint_summary)
breakpoint_index<-breakpoint_summary
names(breakpoint_index)[2]<-"breakpoint_index"


meta<-left_join(meta, breakpoint_index, join_by(lake_name))

meta <- meta %>%
  group_by(lake_name) %>%
  mutate(temperature_breakpoint_bottom_cm = bottom_cm[breakpoint_index],
         temperature_breakpoint_date = date_mid_AD_combo[breakpoint_index]) %>%
  ungroup()

meta <- meta %>%
  mutate(lake_name = factor(lake_name, levels = names(lake_colors)))  

#breakpoints bottom centimeter
ggplot(meta, aes(x=date_mid_AD_combo, y=temp_anomaly_mid_cent_degC)) +
        geom_line()+
  facet_wrap2(~ lake_name, ncol=7, strip.position = "top", strip=strip_themed(background_x = elem_list_rect(fill = lake_colors))) +
        labs(y="Average annual air temperature anomaly from 1951-1980 average (deg C)", x="Date (Common Era)") +
        geom_vline(data=meta %>% select(lake_name,temperature_breakpoint_date) %>% unique(.) %>%  filter(complete.cases(.)), aes(xintercept=temperature_breakpoint_date), color="black",linewidth=0.75) +
        custom_theme()
ggsave("3_Figures/FigX_temperature_breakpoints_date.png",height=4, width=15, units="in")

# write to CSV
lake_breakpoints<-meta %>% select(lake_name, temperature_breakpoint_bottom_cm,temperature_breakpoint_date) %>% unique(.) %>%  filter(complete.cases(.))

write.csv(lake_breakpoints, "2_DataAnalysis/temperature_anomaly_breakpoints.csv")
```

Start here for remaking figures
```{r}
# add in climate data from PRISM
prism <- read.csv("2_DataAnalysis/PRISM/PRISM_ppt_tmean_stable_4km_1895_2021.csv", header = TRUE, skip = 10) %>%
mutate(Name=case_when(Name=="Middle Gaylo"~"Middle Gaylor", 
                      TRUE ~Name)) %>%
  filter(complete.cases(.)) 

# use base R for renaming columns since the dplyr rename() function keeps giving errors when has worked fine in the past. Consistent issue I keep finding.
colnames(prism)[1] <- "lake_name"
colnames(prism)[colnames(prism) == "ppt..mm."] <- "precip_ppt_mm"
colnames(prism)[colnames(prism) == "tmean..degrees.C."] <- "mean_air_temp_degC"
colnames(prism)[colnames(prism) == "Longitude"] <- "longitude_prism"
colnames(prism)[colnames(prism) == "Latitude"] <- "latitude_prism"
colnames(prism)[colnames(prism) == "Elevation..m."] <- "elevation_prism"

prism <- prism %>% mutate(lake_name = factor(lake_name))

# determine the mid century mean from 1951-1981
prism <- prism %>% 
  left_join(.,prism %>% 
      filter(Date > 1950 & Date < 1981) %>% 
      group_by(lake_name) %>% 
      summarize(mean_air_temp_1951_1980_degC = mean(mean_air_temp_degC)), 
    join_by(lake_name)) %>% mutate(mean_air_temp_degC_anomaly_prism=mean_air_temp_degC-mean_air_temp_1951_1980_degC)

metadata <- metadata %>% left_join(read.csv("2_DataAnalysis/temperature_anomaly_breakpoints.csv", header=T,row.names=1), join_by(lake_name))

# order lake names for plot
metadata$lake_name <- factor(metadata$lake_name, levels = names(lake_colors_2))

ggplot(data=metadata, aes(x=date_mid_AD_combo,y=mean_air_temp_degC_anomaly_combined))+
        facet_wrap2(
    ~ lake_name, ncol = 2, strip.position = "top",
    strip = strip_themed(
      background_x = elem_list_rect(fill = lake_colors_2),
      text_x = elem_list_text(
        color = ifelse(names(lake_colors_2) %in% c("Lightning","Lost","Scott","Skelton"), "white", "black"))))+
        geom_line(col="white") + 
        geom_line(data=prism, aes(x=Date,y=mean_air_temp_degC_anomaly_prism), linetype="solid",col="gray") + 
        geom_line(aes(x=date_mid_AD_combo,y=mean_air_temp_degC_anomaly_extended), linetype="dashed") +
        geom_line(aes(x=date_mid_AD_combo,y=temp_anomaly_mid_cent_degC), linetype="solid") +
        custom_theme() + 
        labs(x = "Date (Common Era)", y = "Average annual air temperature anomaly from 1951-1980 average (deg C)")+
        geom_vline(data = metadata, aes(xintercept = temperature_breakpoint_date), 
    color = "black", linewidth = 0.6)

ggsave("3_Figures/FigX_temperature_histories_anomaly.png", height=10,width=7)
```
There are some warnings here but half of the values for mean_air_temp_degC_anomaly_extended and temp_anomaly_mid_cent_degC are NAs because I wanted to plot them separately. No rows that have NAs for mean_air_temp_degC_anomaly_extended & temp_anomaly_mid_cent_degC) and there are no NA's for mean_air_temp_degC_anomaly_combined so this should be fine. 

By state
```{r}

metadata$state <- factor(metadata$state, levels = c("Washington", "Wyoming", "California"))
metadata$lake_name <- factor(metadata$lake_name, levels=names(lake_colors))

t<-ggplot(data = metadata, aes(x = date_mid_AD_combo, y = mean_air_temp_degC_anomaly_combined, color = lake_name)) +
    facet_wrap2(~ state, ncol = 3, strip.position = "top",
                strip = strip_themed(background_x = elem_list_rect(fill = "white"))) +
    geom_line(col = "white") +
    geom_line(aes(x = date_mid_AD_combo, y = mean_air_temp_degC_anomaly_extended, color = lake_name), linetype = "dashed", linewidth=1) +
    geom_line(aes(x = date_mid_AD_combo, y = temp_anomaly_mid_cent_degC, color = lake_name), linetype = "solid", linewidth=1) +
    custom_theme() +
    labs(
        x = "Date (Common Era)",
        y = "Average annual air temperature anomaly
        from 1951-1980 average (deg C)", 
        color = "Lake")+
    scale_color_manual(values = lake_colors)+
        xlim(1800,2021)
        # if you want vertical lines for breakpoints:
        # geom_vline(data = metadata, aes(xintercept = temperature_breakpoint_date, color = lake_name), linewidth = 0.6)

ggsave("3_Figures/FigX_temperature_histories_anomaly_state.png", height=4,width=10)
```


# 5. Nitrogen isotope data

### - breakpoint analysis for d15N
```{r}
meta <- metadata %>% filter(is.na(d15N_anomaly_mean_1800_1850)==F) %>% arrange(lake_name, desc(bottom_cm))

breakpoint_summary<-data.frame(lake_name=NULL,breakpoint_1=NULL, breakpoint_2=NULL)
for(i in 1:14){
sub<-meta[meta$lake_name==unique(meta$lake_name)[i],names(meta)%in%c("sample_id","d15N_anomaly_mean_1800_1850")]
sub<-ts(-(sub$d15N_anomaly_mean_1800_1850), start=1,end=nrow(sub), frequency = 1)

## estimate breakpoints
bp.ri <- breakpoints(sub ~ 1, h = 5)
#plot(bp.ri)
sum<-summary(bp.ri)
one<-sum$breakpoints[1,]
two<-sum$breakpoints[2,]

## fit segmented model with two breaks from minimized BIC
fac.ri <- breakfactor(bp.ri, breaks = 2, label = "seg")
fm.ri <- lm(sub ~ 0 + fac.ri)
#summary(fm.ri)

## Visualization
plot(sub, main=unique(meta$lake_name)[i])
lines(as.vector(time(sub)), fitted(fm.ri), col = 4)

breakpoint_summary<-rbind(breakpoint_summary, data.frame(lake_name=unique(meta$lake_name)[i],breakpoint_1=one[is.na(one)==F], breakpoint_2_1=two[is.na(two)==F][1], breakpoint_2_2=two[is.na(two)==F][2]))
}


print(breakpoint_summary)

# visually pick the first positive breakpoint breakpoints from plots and the breakpoint_summary
breakpoint_index <- c("Black Rock" = 16,"Bullfrog"= 33,"Canyon" = 34,"Crescent"= 28,"Eyrie" = 30, "Footprint" = 32, "Lightning" = 26, "Lost" = 30,"Louise"=38,"Middle Gaylor"= 34,"Monogram"=62,"Scott" = 22,"Skelton"=41,"Soldier"=34)

breakpoint_index<-as.data.frame(breakpoint_index)
breakpoint_index$lake_name<-rownames(breakpoint_index)
rownames(breakpoint_index)<-NULL

meta<-left_join(meta, breakpoint_index, join_by(lake_name))

meta <- meta %>%
  group_by(lake_name) %>%
  mutate(d15N_breakpoint_bottom_cm = bottom_cm[breakpoint_index],
         d15N_breakpoint_date = date_mid_AD_combo[breakpoint_index]) %>%
  ungroup()

lake_breakpoints<-meta %>% select(lake_name, d15N_breakpoint_bottom_cm, d15N_breakpoint_date) %>% unique(.) %>%  filter(complete.cases(.))

write.csv(lake_breakpoints, "2_DataAnalysis/d15N_breakpoints.csv")
```
Note: used first positive breakpoint

Start here for remaking figures
```{r}
meta <- metadata %>% left_join(read.csv("2_DataAnalysis/d15N_breakpoints.csv", header=T,row.names=1), join_by(lake_name))

meta <- meta %>%  mutate(lake_name = factor(lake_name, levels = names(lake_colors_2)))  

ggplot(data = meta, aes(x = date_mid_AD_combo, y = d15N_anomaly_mean_1800_1850)) +
  facet_wrap2(~ lake_name, ncol = 2, strip.position = "top",
    strip = strip_themed(
      background_x = elem_list_rect(fill = lake_colors_2),
      text_x = elem_list_text(
        color = ifelse(names(lake_colors_2) %in% c("Lightning","Lost","Scott","Skelton"), "white", "black")))) +
  geom_line() +
  scale_y_reverse() +
  custom_theme() +
  labs(x = "Date (Common Era)",
       y = expression(delta^15 * "N anomaly from 1800-1850 mean")) +
  geom_vline(data = meta ,
    aes(xintercept = d15N_breakpoint_date),
    color = "black", linewidth = 0.6)

ggsave("3_Figures/FigX_d15N_anomaly_from_1800_1850.png", height=10,width=7)
```

By state
```{r}
meta <- meta %>% filter(date_mid_AD_combo >= 1800 & is.na(d15N_anomaly_mean_1800_1850)==F)

meta <- meta %>%  mutate(lake_name = factor(lake_name, levels = names(lake_colors)),
                         state = factor(state,levels=c("Washington","Wyoming","California")))  

n <-ggplot(data = meta, aes(x = date_mid_AD_combo, y = d15N_anomaly_mean_1800_1850, color = lake_name)) +
    facet_wrap2(~ state, ncol = 3, strip.position = "top",
                strip = strip_themed(background_x = elem_list_rect(fill = "white"))) +
    geom_line(linewidth=1) +
    custom_theme() +
    labs(
        x = "Date (Common Era)",
        y = expression(delta^15 * "N anomaly from 1800-1850 mean"), 
        color = "Lake")+
    scale_color_manual(values = lake_colors)+
        xlim(1800,2022)+
        scale_y_reverse()
        # if you want vertical lines for the breakpoints
        # geom_vline(data = metadata, aes(xintercept = d15N_breakpoint_date, color = lake_name), linewidth = 0.6)

ggsave("3_Figures/FigX_d15N_anomaly_state_1800.png", height=4,width=10)
```



## - plotted against modern atmospheric N deposition data

```{r}
library(sf)
library(mapview)
# part 1
# lagos data
hu12<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/1_LoadData/LAGOS/LAGOS-LOCUS_lake_information/lake_information.csv") %>% filter(lake_centroidstate%in%c("WA","CA","WY"))

# lake core GPS coordinates
cores<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2024-12-05_sample_data_dates.csv") %>% select(lake_name, lat, lon, state)

# use mapview to figure out the hu12_zoneid and lagoslakeid for each of the lakes with sediment cores
points_sf1 <- st_as_sf(hu12, coords = c("lake_lon_decdeg", "lake_lat_decdeg"), crs = 4326)
points_sf2 <- st_as_sf(cores, coords = c("lon", "lat"), crs = 4326)
mapview(points_sf1, color = "blue") + mapview(points_sf2, color = "red")

# part 2
cores_lagos<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/1_LoadData/LAGOS/LAGOS_core_connect.csv")

lagos_atm <- read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/1_LoadData/LAGOS/zone_atmosphere.csv") %>% filter(variable_name %in% c("totaldepnitrogen_kgperha" ,   "totaldepsulfur_kgperha") & spatial_division=="hu12") %>% filter(zoneid %in% cores_lagos$hu12_zoneid)

# rename the huc12_zoneid so it will merge with the core names
lagos_atm <- lagos_atm %>% select(hu12_zoneid = zoneid, year, variable_name, value)

# convert the value to numeric 
lagos_atm$value<-as.numeric(lagos_atm$value)

# calculate the mean kg/ha 
mean_n_dep<-lagos_atm %>% filter(variable_name=="totaldepnitrogen_kgperha") %>% group_by(hu12_zoneid) %>%
        summarize(mean_n_dep_kgperha=mean(value))

mean_n_dep<-left_join(cores_lagos,mean_n_dep, join_by(hu12_zoneid)) %>% mutate(state=lake_centroidstate) %>% select(-lake_centroidstate)

write.csv(mean_n_dep,paste0("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/",Sys.Date(),"_NADP_mean_N_deposition.csv"))

# read in metadata, calculate max difference in nitrogen deposition, and merge with mean nitrogen deposition data
ndep_niso<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2025-02-03_sample_data_dates.csv")  

ndep_niso<-ndep_niso%>% group_by(lake_name) %>% 
        summarize(max_d15N_change=max(abs(d15N_diff_from_start), na.rm=T)) %>% inner_join(.,mean_n_dep, join_by(lake_name))

#rm(list=setdiff(ls(), "ndep_niso"))

ndep_niso$lake_name<-factor(ndep_niso$lake_name, levels=names(lake_colors))

ggplot(ndep_niso, aes(x = max_d15N_change, y = mean_n_dep_kgperha, color = lake_name, shape=state)) +
        geom_point(size=6) +
        scale_color_manual(values = lake_colors) +
        custom_theme()+
        labs(color="Lake",
             x="Magnitude of change in nitrogen isotopes in the sediment core (per mille)",
             y="Mean nitrogen deposition from 2000-2017 (kg/ha)",
             shape="State") +
          theme(panel.grid.minor = element_blank(),
                panel.grid.major = element_blank())


cor.test(ndep_niso$max_d15N_change,ndep_niso$mean_n_dep_kgperha)


# run quick lm (pval: 0.12)
summary(lm(ndep_niso$max_d15N_change~ndep_niso$mean_n_dep_kgperha))

ggsave("3_Figures/FigX_modern_Ndep_mag_d15N.png", height=6,width=8)

```

# 6. Temp & N together
```{r}
# update custom_theme with slightly larger font
custom_theme <- function() {
  theme_bw() +
    theme(
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),  
      text = element_text(color = "black", size = 17),
      axis.text = element_text(color = "black",size = 17),
      axis.title = element_text(color = "black",size = 17),
      axis.title.x = element_text(margin = margin(t = 10)),
      axis.title.y = element_text(margin = margin(r = 10)),
      plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, size = 12),
      legend.text = element_text(size = 17),
      legend.title = element_text(size = 17,hjust = 0.5),
      strip.text = element_text(size = 17, color = "black"))}

# add in climate data from PRISM
prism <- read.csv("2_DataAnalysis/PRISM/PRISM_ppt_tmean_stable_4km_1895_2021.csv", header = TRUE, skip = 10) %>%
        mutate(Name=case_when(Name=="Middle Gaylo"~"Middle Gaylor", 
                              TRUE ~Name)) %>%
        filter(complete.cases(.)) 

# use base R for renaming columns since the dplyr rename() function keeps giving errors when has worked fine in the past. Consistent issue I keep finding.
colnames(prism)[1] <- "lake_name"
colnames(prism)[colnames(prism) == "ppt..mm."] <- "precip_ppt_mm"
colnames(prism)[colnames(prism) == "tmean..degrees.C."] <- "mean_air_temp_degC"
colnames(prism)[colnames(prism) == "Longitude"] <- "longitude_prism"
colnames(prism)[colnames(prism) == "Latitude"] <- "latitude_prism"
colnames(prism)[colnames(prism) == "Elevation..m."] <- "elevation_prism"

prism <- prism %>% mutate(lake_name = factor(lake_name))

# determine the mid century mean from 1951-1981
prism <- prism %>% 
        left_join(.,prism %>% 
                          filter(Date > 1950 & Date < 1981) %>% 
                          group_by(lake_name) %>% 
                          summarize(mean_air_temp_1951_1980_degC = mean(mean_air_temp_degC)), 
                  join_by(lake_name)) %>% mutate(mean_air_temp_degC_anomaly_prism=mean_air_temp_degC-mean_air_temp_1951_1980_degC)

metadata <- metadata %>% left_join(read.csv("2_DataAnalysis/temperature_anomaly_breakpoints.csv", header=T,row.names=1), join_by(lake_name))

# order lake names for plot
metadata$lake_name <- factor(metadata$lake_name, levels = names(lake_colors_2))

metadata$state <- factor(metadata$state, levels = c("Washington", "Wyoming", "California"))
metadata$lake_name <- factor(metadata$lake_name, levels=names(lake_colors))

t<-ggplot(data = metadata, aes(x = date_mid_AD_combo, y = mean_air_temp_degC_anomaly_combined, color = lake_name)) +
        facet_wrap2(~ state, ncol = 3, strip.position = "top",
                    strip = strip_themed(background_x = elem_list_rect(fill = "white"))) +
        geom_line(col = "white") +
        geom_line(aes(x = date_mid_AD_combo, y = mean_air_temp_degC_anomaly_extended, color = lake_name), linetype = "dashed", linewidth=1) +
        geom_line(aes(x = date_mid_AD_combo, y = temp_anomaly_mid_cent_degC, color = lake_name), linetype = "solid", linewidth=1) +
        custom_theme() +
        labs(x = "",
                y = "Average annual air 
temperature anomaly from
1951-1980 mean (deg C)", 
                color = "Lake")+
        scale_color_manual(values = lake_colors)+
        xlim(1800,2021) +
        theme(axis.title.x = element_blank(),
              axis.text.x = element_blank(),
              legend.position = "none")


## NITROGEN

n <- ggplot(data = metadata, aes(x = date_mid_AD_combo, y = d15N_anomaly_mean_1800_1850, color = lake_name)) +
  facet_wrap(~ state, ncol = 3, strip.position = "top") +  # Keep faceting but without labels
  geom_line(linewidth = 1) +
  custom_theme() +
  labs(
    x = "Date (Common Era)",
    y = "d15N anomaly\nfrom 1800-1850 mean") +
  scale_color_manual(values = lake_colors) +
scale_x_continuous(
    limits = c(1800, 2022), 
    breaks = c(1800, 1850, 1900, 1950, 2000),  
    labels = c(1800, "", 1900, "", 2000)) + 
  scale_y_reverse() +
  theme(
    legend.position = "none",  
    strip.text = element_blank(), 
    strip.background = element_blank()  
  )



(t/n)

ggsave("3_Figures/FigX_temperature_nitrogen_combined.png",height=7, width=9.5, units="in")

ggplot(data = metadata, aes(x = date_mid_AD_combo, y = d15N_anomaly_mean_1800_1850, color = lake_name)) +
  facet_wrap(~ state, ncol = 3, strip.position = "top") +  # Keep faceting but without labels
  geom_line(linewidth = 3) +
  custom_theme() +
  labs(
    x = "Date (Common Era)",
    y = expression(delta^15 * "N anomaly from 1800-1850 mean"),
    color="Lake") +
  scale_color_manual(values = lake_colors) +
  xlim(1800, 2022) +
  scale_y_reverse() +
  theme(    strip.text = element_blank(), 
    strip.background = element_blank())

ggsave("3_Figures/FigX_temperature_nitrogen_legend.png",height=5, width=9.5, units="in")

```



# 7. Map
```{r}
custom_theme <- function() {
  theme_bw() +
    theme(
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),  
      text = element_text(color = "black", size = 17),
      axis.text = element_text(color = "black",size = 17),
      axis.title = element_text(color = "black",size = 17),
      axis.title.x = element_text(margin = margin(t = 10)),
      axis.title.y = element_text(margin = margin(r = 10)),
      plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, size = 12),
      legend.text = element_text(size = 17),
      legend.title = element_text(size = 17,hjust = 0.5),
      strip.text = element_text(size = 17, color = "black"))}
```

Plot the western United States
```{r}
# Step 1: Load state boundary data (already loaded in previous code)
all_states <- st_read("2_DataAnalysis/cb_2018_us_state_5m/cb_2018_us_state_5m.shp")

# Step 2: Subset for Western U.S. states
west <- subset(all_states, NAME %in% c("Wyoming", "Colorado", "Idaho", "Utah", 
                                       "Montana", "California", "Washington", 
                                       "Oregon", "Arizona", "New Mexico", "Nevada"))

# Step 3: Combine all selected states into one polygon
west_combined <- west %>%
  st_union() %>%  # Union geometries into one
  st_make_valid()  # Ensure validity of the resulting polygon

# Convert to an sf object
west_combined_sf <- st_sf(geometry = west_combined)

# Step 4: Load the map data (for the states)
states <- map_data("state")

# Step 5: Subset for Western U.S. states
west_states <- subset(states, region %in% c("wyoming", "colorado", "idaho", "utah", 
                                            "montana", "california", "washington", 
                                            "oregon", "arizona", "new mexico", "nevada"))

# Step 6: Convert the map data to sf format
west_sf <- st_as_sf(west_states, coords = c("long", "lat"), crs = 4326)

# Step 7: Convert the geometries to POLYGON (if they are MULTILINESTRING)
west_sf <- st_cast(st_combine(west_sf), "POLYGON")

# Step 8: Define bounding box for Western U.S.
lon_min <- -125
lon_max <- -100
lat_min <- 24
lat_max <- 50

# Create bounding box as an sf object (bounding box for the Western U.S.)
bbox <- st_as_sf(data.frame(
  x = c(lon_min, lon_max, lon_max, lon_min, lon_min),
  y = c(lat_min, lat_min, lat_max, lat_max, lat_min),
  ID = 1
), coords = c("x", "y"), crs = 4326)

# Step 9: Fetch the elevation data (SRTM) for the bounding box (30m resolution)
elevation_data <- get_elev_raster(bbox, z = 6)  # 30m resolution

# Step 10: Check CRS of the elevation data and reproject the state polygons
crs(elevation_data)  # Check the CRS of the elevation data
west_combined_sf <- st_transform(west_combined_sf, crs = crs(elevation_data))  # Reproject to match CRS

# Step 11: Convert the combined sf object to a Spatial object for raster masking
west_sp <- as(west_combined_sf, "Spatial")

# Step 12: Mask the raster with the combined state polygons (only keeping values inside the states)
elevation_subset <- mask(elevation_data, west_sp)

# Step 13: Plot the masked elevation data
#plot(elevation_subset)

# Step 14: Convert the masked raster to a dataframe for ggplot2
elevation_df <- as.data.frame(raster::rasterToPoints(elevation_subset), stringsAsFactors = FALSE)
colnames(elevation_df) <- c("longitude", "latitude", "elevation")

# add in a points for the lakes
pts <- metadata %>% filter(lake_name %in% c("Crescent", "Monogram", "Skelton", "Footprint", "Lost", "Bullfrog")) %>% select(lake_name, lat, lon) %>% distinct(.)


# Step 15: Plot using ggplot2
ggplot(elevation_df, aes(x = longitude, y = latitude, fill = elevation)) +
  geom_tile() +
  scale_fill_gradientn(
    colors = c("darkolivegreen3", "saddlebrown", "white"),
    values = scales::rescale(c(-832, 2000, 4195)),  # Rescale values to 0-1 range
    limits = c(-832, 4195),  # Set the data limits for the fill scale
    oob = scales::squish  # Handle values outside the range gracefully
  ) +
  coord_quickmap() +
  custom_theme() +
  labs(fill = "Elevation (m)") +
        theme(axis.title.x = element_blank(), axis.title.y = element_blank())+
geom_point(data = pts, aes(x = lon, y = lat), 
             color="black", fill=NA,size = 4, stroke=2, shape = 22,inherit.aes = FALSE) 


ggsave("3_Figures/FigX_map_Western_US_elevation.png", height=6, width=7)

```

Small U.S. map with western states outlined with black
```{r}

# Step 1: Load state boundaries
all_states <- st_read("2_DataAnalysis/cb_2018_us_state_5m/cb_2018_us_state_5m.shp")

# Step 2: Subset for Western U.S. states
west <- subset(all_states, NAME %in% c("Wyoming", "Colorado", "Idaho", "Utah", 
                                       "Montana", "California", "Washington", 
                                       "Oregon", "Arizona", "New Mexico", "Nevada"))

# Step 3: Combine all selected states into one polygon
west_combined <- west %>%
  st_union() %>%  # Union geometries into one
  st_make_valid()  # Ensure validity of the resulting polygon

# Convert to an sf object
west_combined_sf <- st_sf(geometry = west_combined)

# Step 4: Create the plot
ggplot() +
  # Plot all states in black
  geom_sf(data = all_states, fill = "gray", color = "gray") +
  # Overlay Western U.S. states in green
  geom_sf(data = west_combined_sf, fill = "black", color = "black") +
          coord_sf(xlim = c(-125, -66.93457), ylim = c(24.396308, 49.384358), expand = FALSE) +
  theme_minimal() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        panel.grid = element_blank())

ggsave("3_Figures/FigX_map_small_US_map.png", height=1.5, width=2)

```


Washington - Mt. Rainier
```{r}
# boundaries for the sub-plot
lon_min <- -121.927497
lon_max <- -121.577569
lat_min <- 46.747659
lat_max <- 46.977162

# use the boundaries to make a polygon
bbox <- st_bbox(c(xmin = lon_min, xmax = lon_max, 
                  ymin = lat_min, ymax = lat_max), 
                crs = st_crs(4326)) %>%
  st_as_sfc()

# make polygon a sf object
bbox_sf <- st_sf(geometry = bbox)

# grab elevation data
elevation_data <- get_elev_raster(locations = bbox_sf, z = 10)  # z = zoom level

# convert raster to dataframe and give column names
elevation_df <- as.data.frame(rasterToPoints(elevation_data), stringsAsFactors = FALSE)
colnames(elevation_df) <- c("longitude", "latitude", "elevation")

# subset the dataframe for the boundaries box (not done automatically)
elevation_df<-elevation_df %>% filter(longitude > lon_min & longitude < lon_max &
                        latitude > lat_min & latitude < lat_max)

# add in a points for the lakes
pts <- metadata %>% filter(lake_name %in% c("Crescent", "Louise")) %>% select(lake_name, lat, lon) %>% distinct(.)

# plot
ggplot(elevation_df, aes(x = longitude, y = latitude, fill = elevation)) +
  geom_tile() +
  scale_fill_gradientn(
    colors = c("darkolivegreen3", "saddlebrown", "white"),
    values = scales::rescale(c(-832, 2000, 4195)), 
    limits = c(-832, 4195),  
    oob = scales::squish) +
geom_point(data = pts, aes(x = lon, y = lat, color=lake_name), 
             size = 4, shape = 16,inherit.aes = FALSE) +
          scale_color_manual(values = lake_colors) +  
  coord_quickmap() +
  custom_theme() + 
  theme(axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    panel.border = element_blank(),
    plot.background = element_blank(),
    panel.background = element_blank(),
    legend.position = "none" )

ggsave("3_Figures/FigX_map_MORA.png", height=3, width=3, bg="transparent")
```


Washington - North Cascades
```{r}
# boundaries for the sub-plot
lon_min <- -121.332899
lon_max <- -121.232965
lat_min <- 48.527976
lat_max <- 48.583677

# use the boundaries to make a polygon
bbox <- st_bbox(c(xmin = lon_min, xmax = lon_max, 
                  ymin = lat_min, ymax = lat_max), 
                crs = st_crs(4326)) %>%
  st_as_sfc()

# make polygon a sf object
bbox_sf <- st_sf(geometry = bbox)

# grab elevation data
elevation_data <- get_elev_raster(locations = bbox_sf, z = 13)  # z = zoom level

# convert raster to dataframe and give column names
elevation_df <- as.data.frame(rasterToPoints(elevation_data), stringsAsFactors = FALSE)
colnames(elevation_df) <- c("longitude", "latitude", "elevation")

# subset the dataframe for the boundaries box (not done automatically)
elevation_df<-elevation_df %>% filter(longitude > lon_min & longitude < lon_max &
                        latitude > lat_min & latitude < lat_max)

# add in a points for the lakes
pts <- metadata %>% filter(lake_name %in% c("Monogram")) %>% select(lake_name, lat, lon) %>% distinct(.)

# plot
ggplot(elevation_df, aes(x = longitude, y = latitude, fill = elevation)) +
  geom_tile() +
  scale_fill_gradientn(
    colors = c("darkolivegreen3", "saddlebrown", "white"),
    values = scales::rescale(c(-832, 2000, 4195)), 
    limits = c(-832, 4195),  
    oob = scales::squish) +
geom_point(data = pts, aes(x = lon, y = lat, color=lake_name), 
             size = 4, shape = 16,inherit.aes = FALSE) +
          scale_color_manual(values = lake_colors) +  
  coord_quickmap() +
  custom_theme() + 
  theme(axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    panel.border = element_blank(),
    plot.background = element_blank(),
    panel.background = element_blank(),
    legend.position = "none" )

ggsave("3_Figures/FigX_map_NOCA.png", height=3, width=3, bg = "transparent")
```

California - Kings Canyon
```{r}
# boundaries for the sub-plot
lon_min <- -118.449090
lon_max <- -118.350523
lat_min <- 36.736607
lat_max <- 36.804553

# use the boundaries to make a polygon
bbox <- st_bbox(c(xmin = lon_min, xmax = lon_max, 
                  ymin = lat_min, ymax = lat_max), 
                crs = st_crs(4326)) %>%
  st_as_sfc()

# make polygon a sf object
bbox_sf <- st_sf(geometry = bbox)

# grab elevation data
elevation_data <- get_elev_raster(locations = bbox_sf, z = 13)  # z = zoom level

# convert raster to dataframe and give column names
elevation_df <- as.data.frame(rasterToPoints(elevation_data), stringsAsFactors = FALSE)
colnames(elevation_df) <- c("longitude", "latitude", "elevation")

# subset the dataframe for the boundaries box (not done automatically)
elevation_df<-elevation_df %>% filter(longitude > lon_min & longitude < lon_max &
                        latitude > lat_min & latitude < lat_max)

# add in a points for the lakes
pts <- metadata %>% filter(lake_name %in% c("Bullfrog")) %>% select(lake_name, lat, lon) %>% distinct(.)

# plot
ggplot(elevation_df, aes(x = longitude, y = latitude, fill = elevation)) +
  geom_tile() +
  scale_fill_gradientn(
    colors = c("darkolivegreen3", "saddlebrown", "white"),
    values = scales::rescale(c(-832, 2000, 4195)), 
    limits = c(-832, 4195),  
    oob = scales::squish) +
geom_point(data = pts, aes(x = lon, y = lat, color=lake_name), 
             size = 4, shape = 16,inherit.aes = FALSE) +
          scale_color_manual(values = lake_colors) +  
  coord_quickmap() +
  custom_theme() + 
  theme(axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    panel.border = element_blank(),
    plot.background = element_blank(),
    panel.background = element_blank(),
    legend.position = "none" )

ggsave("3_Figures/FigX_map_SEKI.png", height=3, width=3)

```


California - Yosemite
```{r}
# boundaries for the sub-plot
lon_min <- -119.424816
lon_max <- -119.166242
lat_min <- 37.898754
lat_max <- 38.068475


# use the boundaries to make a polygon
bbox <- st_bbox(c(xmin = lon_min, xmax = lon_max, 
                  ymin = lat_min, ymax = lat_max), 
                crs = st_crs(4326)) %>%
  st_as_sfc()

# make polygon a sf object
bbox_sf <- st_sf(geometry = bbox)

# grab elevation data
elevation_data <- get_elev_raster(locations = bbox_sf, z = 13)  # z = zoom level

# convert raster to dataframe and give column names
elevation_df <- as.data.frame(rasterToPoints(elevation_data), stringsAsFactors = FALSE)
colnames(elevation_df) <- c("longitude", "latitude", "elevation")

# subset the dataframe for the boundaries box (not done automatically)
elevation_df<-elevation_df %>% filter(longitude > lon_min & longitude < lon_max &
                        latitude > lat_min & latitude < lat_max)

# add in a points for the lakes
pts <- metadata %>% filter(lake_name %in% c("Skelton", "Soldier", "Middle Gaylor")) %>% select(lake_name, lat, lon) %>% distinct(.)

# plot
ggplot(elevation_df, aes(x = longitude, y = latitude, fill = elevation)) +
  geom_tile() +
  scale_fill_gradientn(
    colors = c("darkolivegreen3", "saddlebrown", "white"),
    values = scales::rescale(c(-832, 2000, 4195)), 
    limits = c(-832, 4195),  
    oob = scales::squish) +
geom_point(data = pts, aes(x = lon, y = lat, color=lake_name), 
             size = 4, shape = 16,inherit.aes = FALSE) +
          scale_color_manual(values = lake_colors) +  
  coord_quickmap() +
  custom_theme() + 
  theme(axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    panel.border = element_blank(),
    plot.background = element_blank(),
    panel.background = element_blank(),
    legend.position = "none" )

ggsave("3_Figures/FigX_map_YOSE.png", height=3, width=3)

```


Wyoming - Wind River
```{r}
# boundaries for the sub-plot
lon_min <- -109.036309
lon_max <- -108.973132
lat_min <- 42.627231
lat_max <- 42.667863


# use the boundaries to make a polygon
bbox <- st_bbox(c(xmin = lon_min, xmax = lon_max, 
                  ymin = lat_min, ymax = lat_max), 
                crs = st_crs(4326)) %>%
  st_as_sfc()

# make polygon a sf object
bbox_sf <- st_sf(geometry = bbox)

# grab elevation data
elevation_data <- get_elev_raster(locations = bbox_sf, z = 13)  # z = zoom level

# convert raster to dataframe and give column names
elevation_df <- as.data.frame(rasterToPoints(elevation_data), stringsAsFactors = FALSE)
colnames(elevation_df) <- c("longitude", "latitude", "elevation")

# subset the dataframe for the boundaries box (not done automatically)
elevation_df<-elevation_df %>% filter(longitude > lon_min & longitude < lon_max &
                        latitude > lat_min & latitude < lat_max)

# add in a points for the lakes
pts <- metadata %>% filter(lake_name %in% c("Footprint", "Eyrie", "Lightning","Canyon","Black Rock")) %>% select(lake_name, lat, lon) %>% distinct(.)

# plot
ggplot(elevation_df, aes(x = longitude, y = latitude, fill = elevation)) +
  geom_tile() +
  scale_fill_gradientn(
    colors = c("darkolivegreen3", "saddlebrown", "white"),
    values = scales::rescale(c(-832, 2000, 4195)), 
    limits = c(-832, 4195),  
    oob = scales::squish) +
geom_point(data = pts, aes(x = lon, y = lat, color=lake_name), 
             size = 4, shape = 16,inherit.aes = FALSE) +
          scale_color_manual(values = lake_colors) +  
  coord_quickmap() +
  custom_theme() + 
  theme(axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    panel.border = element_blank(),
    plot.background = element_blank(),
    panel.background = element_blank(),
    legend.position = "none" )

ggsave("3_Figures/FigX_map_WIND.png", height=3, width=3)

```

Wyoming - Snowy
```{r}
# boundaries for the sub-plot
lon_min <- -106.305614
lon_max <- -106.242821
lat_min <- 41.351713
lat_max <- 41.394073

# use the boundaries to make a polygon
bbox <- st_bbox(c(xmin = lon_min, xmax = lon_max, 
                  ymin = lat_min, ymax = lat_max), 
                crs = st_crs(4326)) %>%
  st_as_sfc()

# make polygon a sf object
bbox_sf <- st_sf(geometry = bbox)

# grab elevation data
elevation_data <- get_elev_raster(locations = bbox_sf, z = 13)  # z = zoom level

# convert raster to dataframe and give column names
elevation_df <- as.data.frame(rasterToPoints(elevation_data), stringsAsFactors = FALSE)
colnames(elevation_df) <- c("longitude", "latitude", "elevation")

# subset the dataframe for the boundaries box (not done automatically)
elevation_df<-elevation_df %>% filter(longitude > lon_min & longitude < lon_max &
                        latitude > lat_min & latitude < lat_max)

# add in a points for the lakes
pts <- metadata %>% filter(lake_name %in% c("Lost", "Scott")) %>% select(lake_name, lat, lon) %>% distinct(.)

# plot
ggplot(elevation_df, aes(x = longitude, y = latitude, fill = elevation)) +
  geom_tile() +
  scale_fill_gradientn(
    colors = c("darkolivegreen3", "saddlebrown", "white"),
    values = scales::rescale(c(-832, 2000, 4195)), 
    limits = c(-832, 4195),  
    oob = scales::squish) +
geom_point(data = pts, aes(x = lon, y = lat, color=lake_name), 
             size = 4, shape = 16,inherit.aes = FALSE) +
          scale_color_manual(values = lake_colors) +  
  coord_quickmap() +
  custom_theme() + 
  theme(axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    panel.border = element_blank(),
    plot.background = element_blank(),
    panel.background = element_blank(),
    legend.position = "none" )

ggsave("3_Figures/FigX_map_SNOW.png", height=3, width=3)

```


# 8. Assign unknown trophic mode
For ESVs with unknown trophic modes (comprising 7.8% of the total reads including fungi, and 8.8% if fungi are excluded), we assessed the proportion of the different trophic modes within each subdivision or divison, if necessary, and assigned the unknown ESVs to the most frequent (most abundant) trophic level (heterotrophic protists or phytoplankton). For the few remaining taxa within each division and subdivision that had unknown trophic mode, we placed them in the heterotrophic protists groups. These unknown functions accounted for (0.0002071534) of total reads with fungi and . 
```{r}
# read in the functional assignment file remove ~4k taxa that assign to fungi
tax_fun<-read.csv("2_DataAnalysis/V9_Taxonomy_Function.csv", header=T, row.names=1) %>% column_to_rownames(.,var="asv_code") %>%  mutate(trophic_mode = replace_na(trophic_mode, "unknown")) %>% filter(!subdivision=="Fungi")
tax_fun <- as.matrix(tax_fun) # convert to matrix
ps_V9_norm_sub<-ps_V9_norm
tax_table(ps_V9_norm_sub) <- tax_table(tax_fun) # replace taxonomy table in the phyloseq object
rm(tax_fun)

# unknowns
ps_V9_norm_sub2<-subset_taxa(ps_V9_norm_sub, trophic_mode %in%c("unknown"))
tax_tab<-as.data.frame(ps_V9_norm_sub2@tax_table)
table(tax_tab$subdivision)

    #    Alveolata_X           Cercozoa     Chrompodellids       Colponemidia      Cryptophyta_X 
    #              1                416                 23                  1                 19 
    # Dinoflagellata          Discoba_X         Euglenozoa       Foraminifera            Gyrista 
    #            377                  8                284                 13                152 
    #   Haptophyta_X Hemimastigophora_X      Nibbleridia_X    Stramenopiles_X 
    #             13                 11                  1                  1 

# go through each unknown individually and see what most of the ESVs assign to
ps_V9_norm_sub2<-subset_taxa(ps_V9_norm_sub, subdivision %in%c("Stramenopiles_X"))
ps_V9_norm_sub2<-subset_taxa(ps_V9_norm_sub, division %in%c("Stramenopiles"))
tax_tab<-as.data.frame(ps_V9_norm_sub2@tax_table)
table(tax_tab$trophic_mode)

# few stats

# What is the proportion of reads for the unknown group going into heterotrophic protists
ps_V9_norm_sub2<-subset_taxa(ps_V9_norm_sub, subdivision %in% c("Colponemidia", "Hemimastigophora_X", "Nibbleridia_X", "Foraminifera"))

# percent of total (fungi included)
round(sum(colSums(ps_V9_norm_sub2@otu_table))/sum(colSums(ps_V9_norm@otu_table))*100, digits=2)
# 0.02
# percen of total (fungi excluded)
round(sum(colSums(ps_V9_norm_sub2@otu_table))/sum(colSums(ps_V9_norm_sub@otu_table))*100, digits=2)
# 0.02


# What is the proportion of reads for all ESVs assigned to "unknown" (if fungi are included)
ps_V9_norm_sub2<-subset_taxa(ps_V9_norm_sub, trophic_mode %in%c("unknown"))
# percent of total
round(sum(colSums(ps_V9_norm_sub2@otu_table))/sum(colSums(ps_V9_norm@otu_table))*100, digits=2)
# 7.80

# What is the proportion of reads for all ESVs assigned to "unknown" (if fungi are excluded)
round(sum(colSums(ps_V9_norm_sub2@otu_table))/sum(colSums(ps_V9_norm_sub@otu_table))*100, digits=2)
#  8.79

```
Alveolata_X - hetero
  heterotrophs              parasites            phototrophs phototrophs/mixotrophs (Alveolata division)
           695                    526                    287                      1 
       unknown 
           402 


Cercozoa - hetero
heterotrophs    parasites      unknown 
         767          153          416 


Chrompodellids - hetero
heterotrophs  phototrophs      unknown 
          16            3           23


Colponemidia - unknown (hetero)
unknown 
      1


Cryptophyta_X - photo
heterotrophs   mixotrophs      unknown 
           5            7           19
heterotrophs   mixotrophs      unknown (Cryptophyta divsiion)
           5            7           19 


Dinoflagellata  - photo   
   phototrophs phototrophs/mixotrophs                unknown 
           284                      1                    377


Discoba_X  - hetero      
heterotrophs      unknown 
         140            8 
 heterotrophs    parasites  phototrophs      unknown (Discoba division)
         429           10           19          292


Euglenozoa - hetero
heterotrophs    parasites  phototrophs      unknown 
         289           10           19          284 


Foraminifera  - unknown (hetero) 
unknown 
     13


Gyrista - Photo
heterotrophs   mixotrophs    parasites  phototrophs  saprotrophs      unknown 
          14            4          287          678            5          152


Haptophyta_X  - photo
mixotrophs    unknown 
        10         13 
mixotrophs    unknown (Haptophyta division)
        10         13 


Hemimastigophora_X - unknown (hetero)
unknown 
     11
unknown (Hemimastigophora division)
     11


Nibbleridia_X  - unknown (hetero)
unknown 
      1 
unknown (Nibbleridia division)
      1 


Stramenopiles_X - hetero
unknown 
      1 
heterotrophs   mixotrophs    parasites  phototrophs  saprotrophs      unknown (Stramenopiles divison)
         420            4          287          678            5          153 
420 + 287 + 5 = 712       4 +678 = 682

phytoplankton: Cryptophyta_X, Dinoflagellata, Gyrista, Haptophyta_X
heterotrophic protists: Alveolata_X, Cercozoa, Chrompodellids, Discoba_X, Euglenozoa, Stramenopiles_X
unknown but will go to heterotrophic protists: Colponemidia, Foraminifera, Hemimastigophora_X, Nibbleridia_X


# 9. Relative abundance, NMDS, LMEs by trophic level
## a. level 1 - phototrophic plankton

```{r}
# read in the functional assignment file remove ~4k taxa that assign to fungi
tax_fun<-read.csv("2_DataAnalysis/V9_Taxonomy_Function.csv", header=T, row.names=1) %>% column_to_rownames(.,var="asv_code") %>%  mutate(trophic_mode = replace_na(trophic_mode, "unknown")) %>% filter(!subdivision=="Fungi")
tax_fun <- as.matrix(tax_fun) # convert to matrix
ps_V9_norm_sub<-ps_V9_norm
tax_table(ps_V9_norm_sub) <- tax_table(tax_fun) # replace taxonomy table in the phyloseq object
rm(tax_fun)
ps_V9_norm_sub<-subset_taxa(ps_V9_norm_sub, trophic_mode %in%c("phototrophs","phototrophs/mixotrophs","mixotrophs") | trophic_mode =="unknown" & subdivision%in%c("Cryptophyta_X", "Dinoflagellata", "Gyrista", "Haptophyta_X"))
# included phototrophs, mixotrophs, and phototrophs/mixotrophs along with four subdivisions with "unknown" functions but the primary trophic mode of other ESVs in this subdivision (or division if there is an _X at the end) is phototrophic, mixotrophic, or a combo of the two


# # double check that we kept all the phototrophs and mixotrophs
# tax_tab<-as.data.frame(ps_V9_norm_sub@tax_table)
# table(tax_tab$trophic_mode)
# 
# # and that when we subset with just the right taxa
# tax_fun<-read.csv("2_DataAnalysis/V9_Taxonomy_Function.csv", header=T, row.names=1) %>% column_to_rownames(.,var="asv_code") %>%  mutate(trophic_mode = replace_na(trophic_mode, "unknown")) %>% filter(!subdivision=="Fungi")
# tax_fun <- as.matrix(tax_fun) # convert to matrix
# ps_V9_norm_sub<-ps_V9_norm
# tax_table(ps_V9_norm_sub) <- tax_table(tax_fun) # replace taxonomy table in the phyloseq object
# rm(tax_fun)
# ps_V9_norm_sub2<-subset_taxa(ps_V9_norm_sub, trophic_mode %in%c("phototrophs","phototrophs/mixotrophs","mixotrophs"))
# tax_tab<-as.data.frame(ps_V9_norm_sub2@tax_table)
# table(tax_tab$trophic_mode)
# 
# # and that we selected ther right unknowns
# tax_fun<-read.csv("2_DataAnalysis/V9_Taxonomy_Function.csv", header=T, row.names=1) %>% column_to_rownames(.,var="asv_code") %>%  mutate(trophic_mode = replace_na(trophic_mode, "unknown")) %>% filter(!subdivision=="Fungi")
# tax_fun <- as.matrix(tax_fun) # convert to matrix
# ps_V9_norm_sub<-ps_V9_norm
# tax_table(ps_V9_norm_sub) <- tax_table(tax_fun) # replace taxonomy table in the phyloseq object
# rm(tax_fun)
# ps_V9_norm_sub2<-subset_taxa(ps_V9_norm_sub, trophic_mode =="unknown" & subdivision%in%c("Cryptophyta_X", "Dinoflagellata", "Gyrista", "Haptophyta_X"))
# tax_tab<-as.data.frame(ps_V9_norm_sub2@tax_table)
# table(tax_tab$subdivision)
# sum(table(tax_tab$subdivision))
# rm(ps_V9_norm_sub2)
```


#### i. NMDS
```{r}
# NMDS plot
set.seed(613)
nmds <- ps_V9_norm_sub %>% ordinate(., method = "NMDS", distance="bray")

nmds_points <- as.data.frame(nmds$points)
nmds_points$sample_id<-rownames(nmds_points)
nmds_meta<-merge(nmds_points,metadata,by="sample_id")
rm(nmds_points)

nmds_meta <- nmds_meta %>%
        mutate(lake_color = lake_colors_3[lake_name])

# make the legend order match the lake_colors list
nmds_meta$lake_name <- factor(nmds_meta$lake_name, levels = names(lake_colors_3))


# add depth
nmds_meta$scaled_depth<-scale(nmds_meta$bottom_cm)
nmds_meta$scaled_depth<-(nmds_meta$scaled_depth+2.519536)


nmds_meta <- nmds_meta %>% mutate(fish_present_binary_YN=case_when(fish_present_binary==0~"No",
                                                                    fish_present_binary==1~"Yes"))

NMDS<-ggplot(data = nmds_meta, aes(x = MDS2, y = MDS1, size = scaled_depth, fill = lake_name, color = fish_present_binary_YN)) +
        geom_point(shape = 21, stroke = 1.2) + 
        custom_theme()+ 
        scale_fill_manual(values = lake_colors_3, name = "Lake") +  
        scale_color_manual(values = c(No="#00000000",Yes = "black")) + 
        labs(x = "NMDS2", y = "NMDS1",
             fill = "Lake",
             color = "Fish present") +
        scale_size_continuous(name = "Scaled Depth", range = c(1, 5), guide = "none") + 
        guides(fill = guide_legend(override.aes = list(color = NA, size=4)))+
        custom_theme() + 
        scale_x_reverse()+
  theme(legend.position = "right",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  guides(color = "none")  +
  annotate("text", x = min(nmds_meta$MDS2), y = max(nmds_meta$MDS1),
                   hjust=1,vjust=1,size = 5,
           label = paste("Stress =", round(nmds$stress, 3))) 

# # with legend for fish present for cropping
# NMDS<-ggplot(data = nmds_meta, aes(x = MDS2, y = MDS1, size = scaled_depth, fill = lake_name, color = fish_present_binary_YN)) +
#         geom_point(shape = 21, stroke = 1.2) +
#         custom_theme()+
#         scale_fill_manual(values = lake_colors_3, name = "Lake") +
#         scale_color_manual(values = c(No="#00000000",Yes = "black")) +
#         labs(x = "NMDS2", y = "NMDS1",
#              fill = "Lake",
#              color = "Fish present") +
#         scale_size_continuous(name = "Scaled Depth", range = c(1, 5), guide = "none") +
#         guides(fill = guide_legend(override.aes = list(color = NA, size=4)))+
#         custom_theme() +
#         scale_x_reverse()+
#   theme(legend.position = "right",
#         panel.grid.major = element_blank(),
#         panel.grid.minor = element_blank()) +
#   guides(color = guide_legend(override.aes = list(size = 4)))  +
#           annotate("text", x = min(nmds_meta$MDS2), y = max(nmds_meta$MDS1),
#                    hjust=1,vjust=1,size = 5,
#            label = paste("Stress =", round(nmds$stress, 3)))

write.csv(nmds_meta %>% select(sample_id, MDS1, MDS2, d15N_anomaly_mean_1800_1850,mean_air_temp_degC_anomaly_combined, fish_present_binary_YN ),"2_DataAnalysis/NMDS_phyto.csv")
```


#### ii. select taxa
```{r}
taxa_colors <- c("#009E73","#E69F00", "#56B4E9", "#D55E00")

# group by taxonomic rank and turn to relative abundance
sub <- ps_V9_norm_sub %>% tax_glom(.,taxrank="subdivision") %>% transform_sample_counts(., function(x) x / sum(x)) %>% psmelt(.)

# subset dataset by taxa with the highest abundance in each group
sub <- sub %>% filter(subdivision%in%c(
        sub %>% filter(Abundance > 0.35) %>% select(subdivision) %>% unique(.) %>% pull() # this is where you select the abundance
        ))

# rename the groups so there isn't an _X
sub <- sub %>% mutate(subdivision= case_when(subdivision=="Chlorophyta_X" ~ "Chlorophyta",
                                             subdivision=="Streptophyta_X" ~ "Streptophyta",
                                             TRUE~subdivision
                                             ))

# add in d15N breakpoints
sub <- sub %>% left_join(read.csv("2_DataAnalysis/d15N_breakpoints.csv", header=T,row.names=1), join_by(lake_name))

# add in temperature breakpoints
sub <- sub %>% left_join(read.csv("2_DataAnalysis/temperature_anomaly_breakpoints.csv", header=T,row.names=1), join_by(lake_name))


# order lake names for plot
sub$lake_name_state <- factor(sub$lake_name_state, levels = names(lake_colors_RA))
```

#### iii. linear mixed effects models
```{r}
# select variables for modeling, add time sequence for each sediment core, switch the sign for nitrogen deposition
lme_data <-sub %>% filter(is.na(d15N_anomaly_mean_1800_1850)==F) %>%
        select(Abundance,
               mean_air_temp_degC_anomaly_combined,
               d15N_anomaly_mean_1800_1850,
               fish_present_binary,
               lake_name,
               subdivision, 
               mid_cm) %>%   
        mutate(d15N_anomaly_mean_1800_1850=(d15N_anomaly_mean_1800_1850*(-1))) %>% 
        group_by(lake_name, subdivision) %>% 
        arrange(desc(mid_cm), .by_group = TRUE) %>%
        mutate(time_seq=row_number()) %>% 
        ungroup()  

# split by fish and fishless lakes
lme_data_fish <- lme_data %>% filter(lake_name %in% c("Louise", "Monogram","Black Rock","Footprint","Lost", "Bullfrog","Middle Gaylor","Scott"))
lme_data_fishless <- lme_data %>% filter(!lake_name %in% c("Louise", "Monogram","Black Rock","Footprint","Lost", "Bullfrog","Middle Gaylor","Scott"))
```

no interactions
```{r}
# no interactions - fishless
model_output<-as_tibble(NULL)
for(i in unique(lme_data$subdivision)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 ,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fishless %>% filter(subdivision == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish = "Fishless")
        model_output <- bind_rows(model_output, model_table)
} ; rm(model); rm(i); rm(model_table)

# no interactions - fish
for(i in unique(lme_data$subdivision)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 + fish_present_binary,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fish %>% filter(subdivision == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish = "Fish")
        model_output <- bind_rows(model_output, model_table)
} ; rm(model); rm(i); rm(model_table)


model_output<-model_output %>%
        mutate(pval0.5=case_when(p.value <= 0.05 ~ "Yes",
                                 p.value > 0.05 ~ "No")) %>%
        mutate(term = case_when(term=="(Intercept)"~"Intercept",
                                term=="mean_air_temp_degC_anomaly_combined"~"Air\ntemperature",
                                term=="d15N_anomaly_mean_1800_1850"~"Nitrogen\ndeposition",
                                term=="fish_present_binary"~"Fish"))%>%
        filter(!term=="Intercept")


#####
model_output$term <- factor(model_output$term, levels = c("Fish","Nitrogen\ndeposition","Air\ntemperature"))

model_output$fish <- factor(model_output$fish, levels = c("Fishless","Fish"))

LME<-ggplot(data = model_output, aes(x = Value, y = term, fill = taxa, color = pval0.5)) +
        geom_point(size = 4, shape = 21, stroke = 1.5) +
        custom_theme()+
        facet_wrap(~fish)+
        scale_fill_manual(values = taxa_colors) +
        scale_color_manual(values = c(No="#00000000",Yes = "black")) +
        labs(x = "Estimate",
             y = "",
             fill = "Taxonomic group",
             color = expression(italic("P") <= 0.05)) +
        theme(strip.background = element_blank())+
        guides(fill = guide_legend(override.aes = list(color = NA)))+
        scale_y_discrete(labels = function(term) {
                ifelse(term == "d15N", expression("-" * Delta*delta^15 * "N (nitrogen deposition)"), term) }) +
        geom_vline(aes(xintercept=0),color="black", linetype = "dashed",linewidth=0.75)

#ggsave("3_Figures/FigX_V9_LME_phytoplankton_no_interactions.png",height=5, width=10, units="in")

#####

write.csv(as.data.frame(model_output %>%
               mutate(term=case_when(term=="Nitrogen\ndeposition"~"Nitrogen deposition",
                      term=="Air\ntemperature"~"Air temperature",
                      term=="Fish"~"Fish"))), "2_DataAnalysis/V9_LME_phytoplankton_model_output_no_interactions.csv")

sig_taxa<-model_output %>% filter(pval0.5=="Yes") %>% pull(taxa) %>% unique(.)
```



interactions of all three and subcombinations
```{r}
# interactions - fishless
model_output<-as_tibble(NULL)
for(i in unique(lme_data$subdivision)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 + mean_air_temp_degC_anomaly_combined*d15N_anomaly_mean_1800_1850 ,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fishless %>% filter(subdivision == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish = "Fishless")
        model_output <- bind_rows(model_output, model_table) 
} ; rm(model); rm(i); rm(model_table)


#interaction of all three
for(i in unique(lme_data$subdivision)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 + fish_present_binary +mean_air_temp_degC_anomaly_combined*d15N_anomaly_mean_1800_1850*fish_present_binary,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fish %>% filter(subdivision == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish="Fish")
        model_output <- bind_rows(model_output, model_table) 
} ; rm(model); rm(i); rm(model_table)

model_output %>%
        mutate(pval0.5=case_when(p.value <= 0.05 ~ "Yes",
                                 p.value > 0.05 ~ "No")) %>% 
        filter(pval0.5 =="Yes" &!term=="(Intercept)") %>% pull(term) %>% unique(.)


model_output<-model_output %>%
        mutate(pval0.5=case_when(p.value <= 0.05 ~ "Yes",
                                 p.value > 0.05 ~ "No")) %>% 
        mutate(term = case_when(term=="(Intercept)"~"Intercept",
                                term=="mean_air_temp_degC_anomaly_combined"~"Air temperature",
                                term=="d15N_anomaly_mean_1800_1850"~"Nitrogen deposition",
                                term=="fish_present_binary"~"Fish",
                                term=="mean_air_temp_degC_anomaly_combined:d15N_anomaly_mean_1800_1850"~"Air temperature X\nnitrogen deposition",
                                term=="mean_air_temp_degC_anomaly_combined:fish_present_binary"~"Fish X\nair temperature",
                                term=="mean_air_temp_degC_anomaly_combined:d15N_anomaly_mean_1800_1850:fish_present_binary"~"Fish X\nair temeprature X\nnitrogen deposition",
                                term=="d15N_anomaly_mean_1800_1850:fish_present_binary" ~ "Fish X\nnitrogen deposition"))%>% 
        filter(!term=="Intercept")

model_output$term <- factor(model_output$term) 

model_output$fish <- factor(model_output$fish, levels = c("Fishless","Fish")) 

ggplot(data = model_output, aes(x = Value, y = term, fill = taxa, color = pval0.5)) +
        geom_point(size = 4, shape = 21, stroke = 1.5) + 
        custom_theme()+ 
        facet_wrap(~fish)+
        scale_fill_manual(values = taxa_colors) + 
        scale_color_manual(values = c(No="#00000000",Yes = "black")) + 
        labs(x = "Estimate", 
             y = "",
             fill = "Taxonomic group",
             color = expression(italic("P") <= 0.05)) +
        theme(strip.background = element_blank())+
        guides(fill = guide_legend(override.aes = list(color = NA)))+ 
        scale_y_discrete(labels = function(term) {
                ifelse(term == "d15N", expression("-" * Delta*delta^15 * "N (nitrogen deposition)"), term) }) +
        geom_vline(aes(xintercept=0),color="black", linetype = "dashed",linewidth=0.75)

ggsave("3_Figures/FigX_V9_LME_phytoplankton_interactions.png",height=5, width=10, units="in")

write.csv(as.data.frame(model_output), "2_DataAnalysis/V9_LME_phytoplankton_model_output_interactions.csv")

#sig_taxa<-model_output %>% filter(pval0.5=="Yes") %>% pull(taxa) %>% unique(.)
```



#### iv. plot for relative abundance
```{r}
# add line thickness for significant taxa
sub <- sub %>%
  mutate(line_thickness = factor(ifelse(subdivision %in% sig_taxa, "Significant", "Non-significant")))


RA<-ggplot(data = sub, aes(x = date_mid_AD_combo, y = Abundance, color = subdivision)) +
  facet_wrap2(
    ~ lake_name_state, ncol = 2, strip.position = "top",
    strip = strip_themed(
      background_x = elem_list_rect(fill = lake_colors_RA),
      text_x = elem_list_text(
        color = ifelse(names(lake_colors_RA) %in% c("Lightning - WY","Lost - WY","Scott - WY","Skelton - CA"), "white", "black")))) +
  labs(x = "Date (Common Era)", 
       y = "Relative abundance (proportion)", 
       color = "Taxonomic group", 
       linetype = "", 
       linewidth=expression("Taxa with model estimates")) +
  geom_line(aes(group = subdivision, linewidth = line_thickness)) +         
  custom_theme() + 
  geom_vline(
    data = sub %>% filter(!is.na(d15N_breakpoint_date)), 
    aes(xintercept = d15N_breakpoint_date, linetype = "N isotope breakpoint"), 
    color = "black", linewidth = 0.75
  ) +
  geom_vline(
    data = sub %>% filter(!is.na(first_stocked_yr) & !lake_name_state%in%c("Skelton - CA","Soldier - CA")), 
    aes(xintercept = first_stocked_yr, linetype = "Year fish first stocked"), 
    color = "black", linewidth = 0.75
  ) +
geom_vline(
    data = sub %>% filter(!is.na(first_stocked_yr) & lake_name_state%in%c("Skelton - CA","Soldier - CA")), 
    aes(xintercept = first_stocked_yr, linetype = "Fish present < 35 years"), 
    color = "gray", linewidth = 0.75
  ) +
        geom_vline(
    data = sub %>% filter(!is.na(temperature_breakpoint_date)), 
    aes(xintercept = temperature_breakpoint_date, linetype = "Temperature breakpoint"), 
    color = "black", linewidth = 0.75
  )+
  scale_color_manual(values = taxa_colors) +
 scale_linetype_manual(
    values = c("N isotope breakpoint" = "dotted", "Year fish first stocked" = "solid", "Fish present < 35 years" = "solid", "Temperature breakpoint" = "dashed"),
    breaks = c("N isotope breakpoint", "Year fish first stocked","Fish present < 35 years", "Temperature breakpoint")) +
        guides(
    linetype = guide_legend(keyheight = 2, order = 1), 
    color = guide_legend(override.aes = list(linewidth = 3), order = 2), 
    linewidth = guide_legend(order = 3) 
  )+ 
  scale_linewidth_manual(values = c("Non-significant" = 0.5, "Significant" = 1.3))

 
```


#### v. plot all together
```{r}

(RA|(NMDS/LME)) + plot_layout(widths = c(1.5, 1))

ggsave("3_Figures/FigX_V9_compiled_L1_phytoplankton_NMDS_RelAbun_LME.png",height=10, width=20, units="in")

```




## b. level 2 - heterotrophic protists
#### i. NMDS
```{r}
# read in the functional assignment file remove ~4k taxa that assign to fungi
tax_fun<-read.csv("2_DataAnalysis/V9_Taxonomy_Function.csv", header=T, row.names=1) %>% column_to_rownames(.,var="asv_code") %>%  mutate(trophic_mode = replace_na(trophic_mode, "unknown")) %>% filter(!subdivision=="Fungi")
tax_fun <- as.matrix(tax_fun) # convert to matrix
ps_V9_norm_sub<-ps_V9_norm
tax_table(ps_V9_norm_sub) <- tax_table(tax_fun) # replace taxonomy table in the phyloseq object
rm(tax_fun)
ps_V9_norm_sub <- subset_taxa(ps_V9_norm_sub, 
  (!trophic_mode %in% c("phototrophs", "phototrophs/mixotrophs", "mixotrophs") & 
   !(subdivision == "Metazoa" & class != "Rotifera")) & 
  !(trophic_mode == "unknown" & !subdivision %in% c("Alveolata_X", "Cercozoa", "Chrompodellids", "Discoba_X", "Euglenozoa", "Stramenopiles_X", "Colponemidia", "Foraminifera", "Hemimastigophora_X", "Nibbleridia_X")))
# remove phototrophic/mixotrophic organisms
# keep only Rotifers from the metazoan subdivision (!(subdivision == "Metazoa" & class != "Rotifera"))
# add in unknowns from the specific groups




# # double check that we removed all the phototrophs and mixotrophs
# tax_tab<-as.data.frame(ps_V9_norm_sub@tax_table)
# table(tax_tab$trophic_mode)# no phytoplankton, 759 unknowns
# table(tax_tab$class=="Rotifera") # 31 rotifers
# 
# 
# # check all Rotifera ESVs included
# tax_fun<-read.csv("2_DataAnalysis/V9_Taxonomy_Function.csv", header=T, row.names=1) %>% column_to_rownames(.,var="asv_code") %>%  mutate(trophic_mode = replace_na(trophic_mode, "unknown")) %>% filter(!subdivision=="Fungi")
# tax_fun <- as.matrix(tax_fun) # convert to matrix
# ps_V9_norm_sub<-ps_V9_norm
# tax_table(ps_V9_norm_sub) <- tax_table(tax_fun) # replace taxonomy table in the phyloseq object
# rm(tax_fun)
# ps_V9_norm_sub <- subset_taxa(ps_V9_norm_sub,
#   class=="Rotifera")
# tax_tab<-as.data.frame(ps_V9_norm_sub@tax_table)
# table(tax_tab$class)
# # 31 Rotifera
# 
# # check all Rotifera ESVs included
# tax_fun<-read.csv("2_DataAnalysis/V9_Taxonomy_Function.csv", header=T, row.names=1) %>% column_to_rownames(.,var="asv_code") %>%  mutate(trophic_mode = replace_na(trophic_mode, "unknown")) %>% filter(!subdivision=="Fungi")
# tax_fun <- as.matrix(tax_fun) # convert to matrix
# ps_V9_norm_sub<-ps_V9_norm
# tax_table(ps_V9_norm_sub) <- tax_table(tax_fun) # replace taxonomy table in the phyloseq object
# rm(tax_fun)
# ps_V9_norm_sub <- subset_taxa(ps_V9_norm_sub,
#   trophic_mode == "unknown" & subdivision %in% c("Alveolata_X", "Cercozoa", "Chrompodellids", "Discoba_X", "Euglenozoa", "Stramenopiles_X", "Colponemidia", "Foraminifera", "Hemimastigophora_X", "Nibbleridia_X"))
# tax_tab<-as.data.frame(ps_V9_norm_sub@tax_table)
# table(tax_tab$subdivision)
#        # Alveolata_X           Cercozoa     Chrompodellids       Colponemidia          Discoba_X 
#        #           1                416                 23                  1                  8 
#        #  Euglenozoa       Foraminifera Hemimastigophora_X      Nibbleridia_X    Stramenopiles_X 
#        #         284                 13                 11                  1                  1 
# table(tax_tab$trophic_mode)
# # 759 unknown trophic_mode and they are the five groups
# 
# # make sure we have all these unknowns in the actual subset dataframe
# tax_fun<-read.csv("2_DataAnalysis/V9_Taxonomy_Function.csv", header=T, row.names=1) %>% column_to_rownames(.,var="asv_code") %>%  mutate(trophic_mode = replace_na(trophic_mode, "unknown")) %>% filter(!subdivision=="Fungi")
# tax_fun <- as.matrix(tax_fun) # convert to matrix
# ps_V9_norm_sub<-ps_V9_norm
# tax_table(ps_V9_norm_sub) <- tax_table(tax_fun) # replace taxonomy table in the phyloseq object
# rm(tax_fun)
# ps_V9_norm_sub <- subset_taxa(ps_V9_norm_sub,
#   (!trophic_mode %in% c("phototrophs", "phototrophs/mixotrophs", "mixotrophs") &
#    !(subdivision == "Metazoa" & class != "Rotifera")) &
#   !(trophic_mode == "unknown" & !subdivision %in% c("Alveolata_X", "Cercozoa", "Chrompodellids", "Discoba_X", "Euglenozoa", "Stramenopiles_X", "Colponemidia", "Foraminifera", "Hemimastigophora_X", "Nibbleridia_X")))
# 
# ps_V9_norm_sub <- subset_taxa(ps_V9_norm_sub,
#   trophic_mode == "unknown" & subdivision %in% c("Alveolata_X", "Cercozoa", "Chrompodellids", "Discoba_X", "Euglenozoa", "Stramenopiles_X", "Colponemidia", "Foraminifera", "Hemimastigophora_X", "Nibbleridia_X"))
# tax_tab<-as.data.frame(ps_V9_norm_sub@tax_table)
# table(tax_tab$subdivision) # matches above
# table(tax_tab$trophic_mode) # matches above

```
heterotrophic protists from unknown trophic mode that have mainly heterotrophic ESVs in the division or subdivision: Alveolata_X, Cercozoa, Chrompodellids, Discoba_X, Euglenozoa, Stramenopiles_X

unknown trophic mode in division or subdivision but will go to heterotrophic protists: Colponemidia, Foraminifera, Hemimastigophora_X, Nibbleridia_X



```{r}
# NMDS plot
set.seed(613)
nmds <- ps_V9_norm_sub %>% ordinate(., method = "NMDS", distance="bray")

nmds_points <- as.data.frame(nmds$points)
nmds_points$sample_id<-rownames(nmds_points)
nmds_meta<-merge(nmds_points,metadata,by="sample_id")
rm(nmds_points)

nmds_meta <- nmds_meta %>%
        mutate(lake_color = lake_colors_3[lake_name])

# make the legend order match the lake_colors list
nmds_meta$lake_name <- factor(nmds_meta$lake_name, levels = names(lake_colors_3))


# add depth
nmds_meta$scaled_depth<-scale(nmds_meta$bottom_cm)
nmds_meta$scaled_depth<-(nmds_meta$scaled_depth+2.519536)


nmds_meta <- nmds_meta %>% mutate(fish_present_binary_YN=case_when(fish_present_binary==0~"No",
                                                                    fish_present_binary==1~"Yes"))

NMDS<-ggplot(data = nmds_meta, aes(x = MDS2, y = MDS1, size = scaled_depth, fill = lake_name, color = fish_present_binary_YN)) +
        geom_point(shape = 21, stroke = 1.2) + 
        custom_theme()+ 
        scale_fill_manual(values = lake_colors_3, name = "Lake") +  
        scale_color_manual(values = c(No="#00000000",Yes = "black")) + 
        labs(x = "NMDS2", y = "NMDS1",
             fill = "Lake",
             color = "Fish present") +
        scale_size_continuous(name = "Scaled Depth", range = c(1, 5), guide = "none") + 
        guides(fill = guide_legend(override.aes = list(color = NA, size=4)))+
        custom_theme() + 
        scale_x_reverse()+
  theme(legend.position = "right",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  guides(color = "none")  +
  annotate("text", x = min(nmds_meta$MDS2), y = max(nmds_meta$MDS1),
                   hjust=1,vjust=1,size = 5,
           label = paste("Stress =", round(nmds$stress, 3))) 

write.csv(nmds_meta %>% select(sample_id, MDS1, MDS2, d15N_anomaly_mean_1800_1850,mean_air_temp_degC_anomaly_combined, fish_present_binary_YN ),"2_DataAnalysis/NMDS_hetero_prot.csv")

```


#### ii. select taxa
```{r}
taxa_colors<-c( "#F0E442" ,"#0072B2" ,"#CC79A7" ,"#999999","#D55E00","#009E73")


# group by taxonomic rank and turn to relative abundance
sub <- ps_V9_norm_sub %>% tax_glom(.,taxrank="subdivision") %>% transform_sample_counts(., function(x) x / sum(x)) %>% psmelt(.)

# subset dataset by taxa with the highest abundance in each group
sub <- sub %>% filter(subdivision%in%c(
        sub %>% filter(Abundance > 0.55) %>% select(subdivision) %>% unique(.) %>% pull() # this is where you select the abundance
        ))

unique(sub$subdivision)

# rename the groups so there isn't an _X
sub <- sub %>% mutate(subdivision= case_when(subdivision=="Evosea_X" ~ "Evosea",
                                             subdivision=="Metazoa" ~ "Rotifera",
                                             TRUE~subdivision
                                             ))
# add in d15N breakpoints
sub <- sub %>% left_join(read.csv("2_DataAnalysis/d15N_breakpoints.csv", header=T,row.names=1), join_by(lake_name))

# add in temperature breakpoints
sub <- sub %>% left_join(read.csv("2_DataAnalysis/temperature_anomaly_breakpoints.csv", header=T,row.names=1), join_by(lake_name))


# order lake names for plot
sub$lake_name_state <- factor(sub$lake_name_state, levels = names(lake_colors_RA))

```



#### iii. linear mixed effects models

```{r}
# select variables for modeling, add time sequence for each sediment core, switch the sign for nitrogen deposition
lme_data <-sub %>% filter(is.na(d15N_anomaly_mean_1800_1850)==F) %>%
        select(Abundance,
               mean_air_temp_degC_anomaly_combined,
               d15N_anomaly_mean_1800_1850,
               fish_present_binary,
               lake_name,
               subdivision, 
               mid_cm) %>%   
        mutate(d15N_anomaly_mean_1800_1850=(d15N_anomaly_mean_1800_1850*(-1))) %>% 
        group_by(lake_name, subdivision) %>% 
        arrange(desc(mid_cm), .by_group = TRUE) %>%
        mutate(time_seq=row_number()) %>% 
        ungroup()  

# split by fish and fishless lakes
lme_data_fish <- lme_data %>% filter(lake_name %in% c("Louise", "Monogram","Black Rock","Footprint","Lost", "Bullfrog","Middle Gaylor","Scott"))
lme_data_fishless <- lme_data %>% filter(!lake_name %in% c("Louise", "Monogram","Black Rock","Footprint","Lost", "Bullfrog","Middle Gaylor","Scott"))
```

no interactions
```{r}
# no interactions - fishless
model_output<-as_tibble(NULL)
for(i in unique(lme_data$subdivision)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 ,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fishless %>% filter(subdivision == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish = "Fishless")
        model_output <- bind_rows(model_output, model_table)
} ; rm(model); rm(i); rm(model_table)

# no interactions - fish
for(i in unique(lme_data$subdivision)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 + fish_present_binary,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fish %>% filter(subdivision == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish = "Fish")
        model_output <- bind_rows(model_output, model_table)
} ; rm(model); rm(i); rm(model_table)


model_output<-model_output %>%
        mutate(pval0.5=case_when(p.value <= 0.05 ~ "Yes",
                                 p.value > 0.05 ~ "No")) %>%
        mutate(term = case_when(term=="(Intercept)"~"Intercept",
                                term=="mean_air_temp_degC_anomaly_combined"~"Air\ntemperature",
                                term=="d15N_anomaly_mean_1800_1850"~"Nitrogen\ndeposition",
                                term=="fish_present_binary"~"Fish"))%>%
        filter(!term=="Intercept")


#####
model_output$term <- factor(model_output$term, levels = c("Fish","Nitrogen\ndeposition","Air\ntemperature"))

model_output$fish <- factor(model_output$fish, levels = c("Fishless","Fish"))

LME<-ggplot(data = model_output, aes(x = Value, y = term, fill = taxa, color = pval0.5)) +
        geom_point(size = 4, shape = 21, stroke = 1.5) +
        custom_theme()+
        facet_wrap(~fish)+
        scale_fill_manual(values = taxa_colors) +
        scale_color_manual(values = c(No="#00000000",Yes = "black")) +
        labs(x = "Estimate",
             y = "",
             fill = "Taxonomic group",
             color = expression(italic("P") <= 0.05)) +
        theme(strip.background = element_blank())+
        guides(fill = guide_legend(override.aes = list(color = NA)))+
        scale_y_discrete(labels = function(term) {
                ifelse(term == "d15N", expression("-" * Delta*delta^15 * "N (nitrogen deposition)"), term) }) +
        geom_vline(aes(xintercept=0),color="black", linetype = "dashed",linewidth=0.75)

# ggsave("3_Figures/FigX_V9_LME_heterotrophic_protists_no_interactions.png",height=5, width=10, units="in")
#####

write.csv(as.data.frame(model_output%>%
               mutate(term=case_when(term=="Nitrogen\ndeposition"~"Nitrogen deposition",
                      term=="Air\ntemperature"~"Air temperature",
                      term=="Fish"~"Fish"))), "2_DataAnalysis/V9_LME_heterotrophic_protists_model_output_no_interactions.csv")

sig_taxa<-model_output %>% filter(pval0.5=="Yes") %>% pull(taxa) %>% unique(.)
```


interactions of all three and subcombinations
```{r}
# interactions - fishless
model_output<-as_tibble(NULL)
for(i in unique(lme_data$subdivision)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 + mean_air_temp_degC_anomaly_combined*d15N_anomaly_mean_1800_1850 ,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fishless %>% filter(subdivision == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish = "Fishless")
        model_output <- bind_rows(model_output, model_table) 
} ; rm(model); rm(i); rm(model_table)


#interaction of all three
for(i in unique(lme_data$subdivision)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 + fish_present_binary +mean_air_temp_degC_anomaly_combined*d15N_anomaly_mean_1800_1850*fish_present_binary,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fish %>% filter(subdivision == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish="Fish")
        model_output <- bind_rows(model_output, model_table) 
} ; rm(model); rm(i); rm(model_table)

model_output %>%
        mutate(pval0.5=case_when(p.value <= 0.05 ~ "Yes",
                                 p.value > 0.05 ~ "No")) %>% 
        filter(pval0.5 =="Yes" &!term=="(Intercept)") %>% pull(term) %>% unique(.)
# [1] "d15N_anomaly_mean_1800_1850"                                                        
# [2] "fish_present_binary"                                                                
# [3] "mean_air_temp_degC_anomaly_combined:d15N_anomaly_mean_1800_1850"                    
# [4] "d15N_anomaly_mean_1800_1850:fish_present_binary"                                    
# [5] "mean_air_temp_degC_anomaly_combined:d15N_anomaly_mean_1800_1850:fish_present_binary"

model_output<-model_output %>%
        mutate(pval0.5=case_when(p.value <= 0.05 ~ "Yes",
                                 p.value > 0.05 ~ "No")) %>% 
        mutate(term = case_when(term=="(Intercept)"~"Intercept",
                                term=="mean_air_temp_degC_anomaly_combined"~"Air temperature",
                                term=="d15N_anomaly_mean_1800_1850"~"Nitrogen deposition",
                                term=="fish_present_binary"~"Fish",
                                term=="mean_air_temp_degC_anomaly_combined:d15N_anomaly_mean_1800_1850"~"Air temperature X\nnitrogen deposition",
                                term=="mean_air_temp_degC_anomaly_combined:fish_present_binary"~"Fish X\nair temperature",
                                term=="mean_air_temp_degC_anomaly_combined:d15N_anomaly_mean_1800_1850:fish_present_binary"~"Fish X\nair temeprature X\nnitrogen deposition",
                                term=="d15N_anomaly_mean_1800_1850:fish_present_binary" ~ "Fish X\nnitrogen deposition"))%>% 
        filter(!term=="Intercept")

model_output$term <- factor(model_output$term) 

model_output$fish <- factor(model_output$fish, levels = c("Fishless","Fish")) 

ggplot(data = model_output, aes(x = Value, y = term, fill = taxa, color = pval0.5)) +
        geom_point(size = 4, shape = 21, stroke = 1.5) + 
        custom_theme()+ 
        facet_wrap(~fish)+
        scale_fill_manual(values = taxa_colors) + 
        scale_color_manual(values = c(No="#00000000",Yes = "black")) + 
        labs(x = "Estimate", 
             y = "",
             fill = "Taxonomic group",
             color = expression(italic("P") <= 0.05)) +
        theme(strip.background = element_blank())+
        guides(fill = guide_legend(override.aes = list(color = NA)))+ 
        scale_y_discrete(labels = function(term) {
                ifelse(term == "d15N", expression("-" * Delta*delta^15 * "N (nitrogen deposition)"), term) }) +
        geom_vline(aes(xintercept=0),color="black", linetype = "dashed",linewidth=0.75)
 
ggsave("3_Figures/FigX_V9_LME_heterotrophic_protists_interactions.png",height=5, width=10, units="in")


write.csv(as.data.frame(model_output), "2_DataAnalysis/V9_LME_heterotrophic_protists_model_output_interactions.csv")

#sig_taxa<-model_output %>% filter(pval0.5=="Yes") %>% pull(taxa) %>% unique(.)
```



#### iv. relative abundance plot
```{r}
# add line thickness for significant taxa
sub <- sub %>%
  mutate(line_thickness = factor(ifelse(subdivision %in% sig_taxa, "Significant", "Non-significant")))

RA<-ggplot(data = sub, aes(x = date_mid_AD_combo, y = Abundance, color = subdivision)) +
  facet_wrap2(
    ~ lake_name_state, ncol = 2, strip.position = "top",
    strip = strip_themed(
      background_x = elem_list_rect(fill = lake_colors_RA),
      text_x = elem_list_text(
        color = ifelse(names(lake_colors_RA) %in% c("Lightning - WY","Lost - WY","Scott - WY","Skelton - CA"), "white", "black")))) +
  labs(x = "Date (Common Era)", 
       y = "Relative abundance (proportion)", 
       color = "Taxonomic group", 
       linetype = "", 
       linewidth=expression("Taxa with model estimates")) +
  geom_line(aes(group = subdivision, linewidth = line_thickness)) +         
  custom_theme() + 
    geom_vline(
    data = sub %>% filter(!is.na(d15N_breakpoint_date)), 
    aes(xintercept = d15N_breakpoint_date, linetype = "N isotope breakpoint"), 
    color = "black", linewidth = 0.75
  ) +
  geom_vline(
    data = sub %>% filter(!is.na(first_stocked_yr) & !lake_name_state %in% c("Skelton - CA","Soldier - CA")), 
    aes(xintercept = first_stocked_yr, linetype = "Year fish first stocked"), 
    color = "black", linewidth = 0.75
  ) +
geom_vline(
    data = sub %>% filter(!is.na(first_stocked_yr) & lake_name_state %in% c("Skelton - CA","Soldier - CA")), 
    aes(xintercept = first_stocked_yr, linetype = "Fish present < 35 years"), 
    color = "gray", linewidth = 0.75
  ) +
        geom_vline(
    data = sub %>% filter(!is.na(temperature_breakpoint_date)), 
    aes(xintercept = temperature_breakpoint_date, linetype = "Temperature breakpoint"), 
    color = "black", linewidth = 0.75
  )+
  scale_color_manual(values = taxa_colors) +
 scale_linetype_manual(
    values = c("N isotope breakpoint" = "dotted", "Year fish first stocked" = "solid", "Fish present < 35 years" = "solid", "Temperature breakpoint" = "dashed"),
    breaks = c("N isotope breakpoint", "Year fish first stocked","Fish present < 35 years", "Temperature breakpoint")) +
        guides(
    linetype = guide_legend(keyheight = 2, order = 1), 
    color = guide_legend(override.aes = list(linewidth = 3), order = 2), 
    linewidth = guide_legend(order = 3) 
  )+
  scale_linewidth_manual(values = c("Non-significant" = 0.5, "Significant" = 1.3))

 
```


#### v. plot all together
```{r}

(RA|(NMDS/LME)) + plot_layout(widths = c(1.5, 1))

ggsave("3_Figures/FigX_V9_compiled_L2_heterotrophic_protist_NMDS_RelAbun_LME.png",height=10, width=20, units="in")

```




## c. level 3 - zooplankton
```{r}
# read in taxonomy assigned in Ch. 2
tax_blast<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/ZooplanktonSedDNA/5_DataAnalysis/BLAST_zooplankton/Max_Bra/5_BLAST_V9_original_single_multiple_updated.csv", row.names=1,na.strings="") %>% column_to_rownames(., var="qseqid") %>% 
   mutate(taxonomic_group = replace_na(taxonomic_group, "Unassigned")) %>% select(Kingdom,taxonomic_group)
tax_blast <- as.matrix(tax_blast) # convert to matrix
ps_V9_norm_sub<-ps_V9_norm
tax_table(ps_V9_norm_sub) <- tax_table(tax_blast) # replace taxonomy table in the phyloseq object
rm(tax_blast)

# congomerate right away to taxonomic_group
ps_V9_norm_sub <- ps_V9_norm_sub %>% tax_glom(., taxrank = "taxonomic_group")
```

#### i. NMDS
```{r}
# NMDS plot
set.seed(613)
nmds <- ps_V9_norm_sub %>% ordinate(., method = "NMDS", distance="bray")

nmds_points <- as.data.frame(nmds$points)
nmds_points$sample_id<-rownames(nmds_points)
nmds_meta<-merge(nmds_points,metadata,by="sample_id")
rm(nmds_points)

nmds_meta <- nmds_meta %>%
        mutate(lake_color = lake_colors_3[lake_name])

# make the legend order match the lake_colors list
nmds_meta$lake_name <- factor(nmds_meta$lake_name, levels = names(lake_colors_3))


# add depth
nmds_meta$scaled_depth<-scale(nmds_meta$bottom_cm)
nmds_meta$scaled_depth<-(nmds_meta$scaled_depth+2.519536)


nmds_meta <- nmds_meta %>% mutate(fish_present_binary_YN=case_when(fish_present_binary==0~"No",
                                                                    fish_present_binary==1~"Yes"))

NMDS<-ggplot(data = nmds_meta, aes(x = MDS2, y = MDS1, size = scaled_depth, fill = lake_name, color = fish_present_binary_YN)) +
        geom_point(shape = 21, stroke = 1.2) + 
        custom_theme()+ 
        scale_fill_manual(values = lake_colors_3, name = "Lake") +  
        scale_color_manual(values = c(No="#00000000",Yes = "black")) + 
        labs(x = "NMDS2", y = "NMDS1",
             fill = "Lake",
             color = "Fish present") +
        scale_size_continuous(name = "Scaled Depth", range = c(1, 5), guide = "none") + 
        guides(fill = guide_legend(override.aes = list(color = NA, size=4)))+
        custom_theme() + 
        scale_x_reverse()+
  theme(legend.position = "right",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  guides(color = "none")  +
  annotate("text", x = min(nmds_meta$MDS2), y = max(nmds_meta$MDS1),
                   hjust=1,vjust=1,size = 5,
           label = paste("Stress =", round(nmds$stress, 3))) 


write.csv(nmds_meta %>% select(sample_id, MDS1, MDS2, d15N_anomaly_mean_1800_1850,mean_air_temp_degC_anomaly_combined, fish_present_binary_YN),"2_DataAnalysis/NMDS_zoop.csv")
```


#### ii. select taxa
```{r}
taxa_colors<-palette.colors(palette = "Okabe-Ito")
taxa_colors<-c("gray50", "#E69F00" ,"#56B4E9" ,"#F0E442","#0072B2","#D55E00" ,"#009E73" ,"#CC79A7")

# group by taxonomic rank and turn to relative abundance
sub <- ps_V9_norm_sub %>% transform_sample_counts(., function(x) x / sum(x)) %>% psmelt(.)

# subset dataset by taxa with the highest abundance in each group
sub <- sub %>% filter(taxonomic_group%in%c(
        sub %>% filter(Abundance > 0.4) %>% select(taxonomic_group) %>% unique(.) %>% pull() # this is where you select the abundance
        ))

unique(sub$taxonomic_group)


# add in d15N breakpoints
sub <- sub %>% left_join(read.csv("2_DataAnalysis/d15N_breakpoints.csv", header=T,row.names=1), join_by(lake_name))

# add in temperature breakpoints
sub <- sub %>% left_join(read.csv("2_DataAnalysis/temperature_anomaly_breakpoints.csv", header=T,row.names=1), join_by(lake_name))



# order lake names for plot
sub$lake_name_state <- factor(sub$lake_name_state, levels = names(lake_colors_RA))


```



#### iii. linear mixed effects models

```{r}
# select variables for modeling, add time sequence for each sediment core, switch the sign for nitrogen deposition
lme_data <-sub %>% filter(is.na(d15N_anomaly_mean_1800_1850)==F) %>%
        select(Abundance,
               mean_air_temp_degC_anomaly_combined,
               d15N_anomaly_mean_1800_1850,
               fish_present_binary,
               lake_name,
               taxonomic_group, 
               mid_cm) %>%   
        mutate(d15N_anomaly_mean_1800_1850=(d15N_anomaly_mean_1800_1850*(-1))) %>% 
        group_by(lake_name, taxonomic_group) %>% 
        arrange(desc(mid_cm), .by_group = TRUE) %>%
        mutate(time_seq=row_number()) %>% 
        ungroup()  

# split by fish and fishless lakes
lme_data_fish <- lme_data %>% filter(lake_name %in% c("Louise", "Monogram","Black Rock","Footprint","Lost", "Bullfrog","Middle Gaylor","Scott"))
lme_data_fishless <- lme_data %>% filter(!lake_name %in% c("Louise", "Monogram","Black Rock","Footprint","Lost", "Bullfrog","Middle Gaylor","Scott"))
```

no interactions
```{r}
# no interactions - fishless
model_output<-as_tibble(NULL)
for(i in unique(lme_data$taxonomic_group)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 ,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fishless %>% filter(taxonomic_group == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish = "Fishless")
        model_output <- bind_rows(model_output, model_table)
} ; rm(model); rm(i); rm(model_table)

# no interactions - fish
for(i in unique(lme_data$taxonomic_group)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 + fish_present_binary,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fish %>% filter(taxonomic_group == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish = "Fish")
        model_output <- bind_rows(model_output, model_table)
} ; rm(model); rm(i); rm(model_table)


model_output<-model_output %>%
        mutate(pval0.5=case_when(p.value <= 0.05 ~ "Yes",
                                 p.value > 0.05 ~ "No")) %>%
        mutate(term = case_when(term=="(Intercept)"~"Intercept",
                                term=="mean_air_temp_degC_anomaly_combined"~"Air\ntemperature",
                                term=="d15N_anomaly_mean_1800_1850"~"Nitrogen\ndeposition",
                                term=="fish_present_binary"~"Fish"))%>%
        filter(!term=="Intercept")


#####
model_output$term <- factor(model_output$term, levels = c("Fish","Nitrogen\ndeposition","Air\ntemperature"))

model_output$fish <- factor(model_output$fish, levels = c("Fishless","Fish"))

LME<-ggplot(data = model_output, aes(x = Value, y = term, fill = taxa, color = pval0.5)) +
        geom_point(size = 4, shape = 21, stroke = 1.5) +
        custom_theme()+
        facet_wrap(~fish)+
        scale_fill_manual(values = taxa_colors) +
        scale_color_manual(values = c(No="#00000000",Yes = "black")) +
        labs(x = "Estimate",
             y = "",
             fill = "Taxonomic group",
             color = expression(italic("P") <= 0.05)) +
        theme(strip.background = element_blank())+
        guides(fill = guide_legend(override.aes = list(color = NA)))+
        scale_y_discrete(labels = function(term) {
                ifelse(term == "d15N", expression("-" * Delta*delta^15 * "N (nitrogen deposition)"), term) }) +
        geom_vline(aes(xintercept=0),color="black", linetype = "dashed",linewidth=0.75)

#ggsave("3_Figures/FigX_V9_LME_zooplankton_no_interactions.png",height=5, width=10, units="in")
#####

write.csv(as.data.frame(model_output%>%
               mutate(term=case_when(term=="Nitrogen\ndeposition"~"Nitrogen deposition",
                      term=="Air\ntemperature"~"Air temperature",
                      term=="Fish"~"Fish"))), "2_DataAnalysis/V9_LME_zooplankton_model_output_no_interactions.csv")

sig_taxa<-model_output %>% filter(pval0.5=="Yes") %>% pull(taxa) %>% unique(.)
```


interactions of all three and subcombinations
```{r}
# interactions - fishless
model_output<-as_tibble(NULL)
for(i in unique(lme_data$taxonomic_group)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 + mean_air_temp_degC_anomaly_combined*d15N_anomaly_mean_1800_1850 ,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fishless %>% filter(taxonomic_group == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish = "Fishless")
        model_output <- bind_rows(model_output, model_table) 
} ; rm(model); rm(i); rm(model_table)


#interaction of all three
for(i in unique(lme_data$taxonomic_group)){
        model <- lme(
                Abundance ~ mean_air_temp_degC_anomaly_combined + d15N_anomaly_mean_1800_1850 + fish_present_binary +mean_air_temp_degC_anomaly_combined*d15N_anomaly_mean_1800_1850*fish_present_binary,
                random = ~ 1 | lake_name,
                correlation = corAR1(form = ~ time_seq),
                data = lme_data_fish %>% filter(taxonomic_group == i))
        # extract model estimates and put into a table for each iteration
        model_summary <- summary(model)
        model_table <- as_tibble(model_summary$tTable, rownames = "term") %>% setNames(make.names(names(.)))
        model_table <- model_table %>% mutate(taxa = i, fish="Fish")
        model_output <- bind_rows(model_output, model_table) 
} ; rm(model); rm(i); rm(model_table)

model_output %>%
        mutate(pval0.5=case_when(p.value <= 0.05 ~ "Yes",
                                 p.value > 0.05 ~ "No")) %>% 
        filter(pval0.5 =="Yes" &!term=="(Intercept)") %>% pull(term) %>% unique(.)
# [1] "mean_air_temp_degC_anomaly_combined:d15N_anomaly_mean_1800_1850"
# [2] "mean_air_temp_degC_anomaly_combined:fish_present_binary"        
# [3] "d15N_anomaly_mean_1800_1850:fish_present_binary"                
# [4] "mean_air_temp_degC_anomaly_combined"                            
# [5] "fish_present_binary"    

model_output<-model_output %>%
        mutate(pval0.5=case_when(p.value <= 0.05 ~ "Yes",
                                 p.value > 0.05 ~ "No")) %>% 
        mutate(term = case_when(term=="(Intercept)"~"Intercept",
                                term=="mean_air_temp_degC_anomaly_combined"~"Air temperature",
                                term=="d15N_anomaly_mean_1800_1850"~"Nitrogen deposition",
                                term=="fish_present_binary"~"Fish",
                                term=="mean_air_temp_degC_anomaly_combined:d15N_anomaly_mean_1800_1850"~"Air temperature X\nnitrogen deposition",
                                term=="mean_air_temp_degC_anomaly_combined:fish_present_binary"~"Fish X\nair temperature",
                                term=="mean_air_temp_degC_anomaly_combined:d15N_anomaly_mean_1800_1850:fish_present_binary"~"Fish X\nair temeprature X\nnitrogen deposition",
                                term=="d15N_anomaly_mean_1800_1850:fish_present_binary" ~ "Fish X\nnitrogen deposition"))%>% 
        filter(!term=="Intercept")

model_output$term <- factor(model_output$term) 

model_output$fish <- factor(model_output$fish, levels = c("Fishless","Fish")) 

ggplot(data = model_output, aes(x = Value, y = term, fill = taxa, color = pval0.5)) +
        geom_point(size = 4, shape = 21, stroke = 1.5) + 
        custom_theme()+ 
        facet_wrap(~fish)+
        scale_fill_manual(values = taxa_colors) + 
        scale_color_manual(values = c(No="#00000000",Yes = "black")) + 
        labs(x = "Estimate", 
             y = "",
             fill = "Taxonomic group",
             color = expression(italic("P") <= 0.05)) +
        theme(strip.background = element_blank())+
        guides(fill = guide_legend(override.aes = list(color = NA)))+ 
        scale_y_discrete(labels = function(term) {
                ifelse(term == "d15N", expression("-" * Delta*delta^15 * "N (nitrogen deposition)"), term) }) +
        geom_vline(aes(xintercept=0),color="black", linetype = "dashed",linewidth=0.75)

ggsave("3_Figures/FigX_V9_LME_zooplankton_interactions.png",height=5, width=10, units="in")


write.csv(as.data.frame(model_output), "2_DataAnalysis/V9_LME_zooplankton_model_output_interactions.csv")

#sig_taxa<-model_output %>% filter(pval0.5=="Yes") %>% pull(taxa) %>% unique(.)
```




#### iv. plot relative abundance
```{r}
# add line thickness for significant taxa
sub <- sub %>%
  mutate(line_thickness = factor(ifelse(taxonomic_group %in% sig_taxa, "Significant", "Non-significant")))

RA<-ggplot(data = sub, aes(x = date_mid_AD_combo, y = Abundance, color = taxonomic_group)) +
  facet_wrap2(
    ~ lake_name_state, ncol = 2, strip.position = "top",
    strip = strip_themed(
      background_x = elem_list_rect(fill = lake_colors_RA),
      text_x = elem_list_text(
        color = ifelse(names(lake_colors_RA) %in% c("Lightning - WY","Lost - WY","Scott - WY","Skelton - CA"), "white", "black")))) +
  labs(x = "Date (Common Era)", 
       y = "Relative abundance (proportion)", 
       color = "Taxonomic group", 
       linetype = "", 
       linewidth=expression("Taxa with model estimates")) +
  geom_line(aes(group = taxonomic_group, linewidth = line_thickness)) +         
  custom_theme() + 
   geom_vline(
    data = sub %>% filter(!is.na(d15N_breakpoint_date)), 
    aes(xintercept = d15N_breakpoint_date, linetype = "N isotope breakpoint"), 
    color = "black", linewidth = 0.75
  ) +
  geom_vline(
    data = sub %>% filter(!is.na(first_stocked_yr) & !lake_name_state %in% c("Skelton - CA","Soldier - CA")), 
    aes(xintercept = first_stocked_yr, linetype = "Year fish first stocked"), 
    color = "black", linewidth = 0.75
  ) +
geom_vline(
    data = sub %>% filter(!is.na(first_stocked_yr) & lake_name_state %in% c("Skelton - CA","Soldier - CA")), 
    aes(xintercept = first_stocked_yr, linetype = "Fish present < 35 years"), 
    color = "gray", linewidth = 0.75
  ) +
        geom_vline(
    data = sub %>% filter(!is.na(temperature_breakpoint_date)), 
    aes(xintercept = temperature_breakpoint_date, linetype = "Temperature breakpoint"), 
    color = "black", linewidth = 0.75
  )+
  scale_color_manual(values = taxa_colors) +
 scale_linetype_manual(
    values = c("N isotope breakpoint" = "dotted", "Year fish first stocked" = "solid", "Fish present < 35 years" = "solid", "Temperature breakpoint" = "dashed"),
    breaks = c("N isotope breakpoint", "Year fish first stocked","Fish present < 35 years", "Temperature breakpoint")) +
        guides(
    linetype = guide_legend(keyheight = 2, order = 1), 
    color = guide_legend(override.aes = list(linewidth = 3), order = 2), 
    linewidth = guide_legend(order = 3) 
  )+
  scale_linewidth_manual(values = c("Non-significant" = 0.5, "Significant" = 1.3))


```


#### v. plot all together
```{r}

(RA|(NMDS/LME)) + plot_layout(widths = c(1.5, 1))

ggsave("3_Figures/FigX_V9_compiled_L3_zooplankton_NMDS_RelAbun_LME.png",height=10, width=20, units="in")

```
Notes: one thing to change would be that we use subdivision for phytoplankton and heterotrophic protists and then taxonomic_group for zooplankton



# 10. Summary figures

## a. NMDS 
### i. by trophic level, state, and stressor
with linear models and t-tests
```{r}
# combine all three of the NMDS data frames
nmds_comb <-rbind(read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/NMDS_phyto.csv", header=T, row.names = 1) %>% 
                   select(sample_id, MDS2,d15N_anomaly_mean_1800_1850, mean_air_temp_degC_anomaly_combined, fish_present_binary_YN) %>% 
                   rename(NMDS=MDS2) %>% 
                   mutate(trophic_level="Phytoplankton"),

 
           read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/NMDS_hetero_prot.csv", header=T, row.names = 1) %>% 
                   select(sample_id, MDS2,d15N_anomaly_mean_1800_1850, mean_air_temp_degC_anomaly_combined, fish_present_binary_YN) %>%
                   rename(NMDS=MDS2) %>% 
                   mutate(trophic_level="Heterotrophic\nprotists"),

 
           read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/NMDS_zoop.csv", header=T, row.names = 1) %>% 
                   select(sample_id, MDS1, d15N_anomaly_mean_1800_1850, mean_air_temp_degC_anomaly_combined, fish_present_binary_YN) %>%
                   rename(NMDS=MDS1) %>% 
                   mutate(trophic_level="Zooplankton")
           )

# add in lake name and state
nmds_comb <- left_join(nmds_comb, metadata %>% select(sample_id, lake_name, state), join_by(sample_id)) 

nmds_comb$lake_name <- factor(nmds_comb$lake_name, levels = names(lake_colors))
nmds_comb$state <- factor(nmds_comb$state, levels = c("Washington", "Wyoming","California"))
nmds_comb$trophic_level <- factor(nmds_comb$trophic_level, levels = c("Phytoplankton", "Heterotrophic\nprotists", "Zooplankton"))


####################
### TEMPERATURE ####
####################

# run linear models, grab r-sq and p-value, only plot pval < 0.05
model_stats <- nmds_comb %>%
  group_by(trophic_level, state) %>%
  summarise(
    lm_fit = list(lm(NMDS ~ mean_air_temp_degC_anomaly_combined, data = cur_data())),
    .groups = "drop"
  ) %>%
  mutate(
    p_value = sapply(lm_fit, function(m) summary(m)$coefficients[2, 4]), # p-val
    r_squared = sapply(lm_fit, function(m) summary(m)$r.squared)
  ) %>%
  filter(p_value < 0.05) %>% 
  mutate(
    label = paste0("R² = ", signif(r_squared, 3)),
    x_pos = max(nmds_comb$mean_air_temp_degC_anomaly_combined, na.rm = TRUE)*0.5, 
    y_pos = 1.2 
  )

# make separate dataframe of only signficant models to plot the lines
significant_models <- nmds_comb %>%
  inner_join(model_stats, by = c("trophic_level", "state"))

# plot
temp <- ggplot(nmds_comb, aes(x = mean_air_temp_degC_anomaly_combined, 
                              y = NMDS, color = lake_name)) +
  facet_grid(trophic_level ~ state) +
  geom_point() +
  scale_color_manual(values = lake_colors) +
  custom_theme() + 
  scale_y_reverse() +
  labs(x = "Average annual air temperature anomaly\nfrom 1951-1980 mean (deg C)",
       color = "Lake") + 
  theme(strip.background = element_rect(fill = "white"),
        strip.text.y = element_blank())

# plot regression lines when significant
if (nrow(significant_models) > 0) {
  temp <- temp + geom_smooth(data = significant_models, 
                             method = "lm", color = "black", se = FALSE)
}

# add in r-squared to plot
temp <- temp + geom_text(data = model_stats, aes(x = x_pos, y = y_pos, label = label),
                         color = "black", size = 4, inherit.aes = FALSE)

#################
### NITROGEN ####
#################
# run linear models, grab r-sq and p-value, only plot pval < 0.05
model_stats <- nmds_comb %>% filter(is.na(d15N_anomaly_mean_1800_1850)==F) %>% 
  group_by(trophic_level, state) %>%
  summarise(
    lm_fit = list(lm(NMDS ~ d15N_anomaly_mean_1800_1850, data = cur_data())),
    .groups = "drop"
  ) %>%
  mutate(
    p_value = sapply(lm_fit, function(m) summary(m)$coefficients[2, 4]), # grab p-val
    r_squared = sapply(lm_fit, function(m) summary(m)$r.squared) # grab r-sq
  ) %>%
  filter(p_value < 0.05) %>% # plot significant models only 
  mutate(
    label = paste0("R² = ", signif(r_squared, 3)),
    x_pos = min(nmds_comb$d15N_anomaly_mean_1800_1850, na.rm = TRUE)*0.6,  
    y_pos = 1.2 
  )

# make separate dataframe of only signficant models to plot the lines
significant_models <- nmds_comb %>% filter(is.na(d15N_anomaly_mean_1800_1850)==F) %>%
  inner_join(model_stats, by = c("trophic_level", "state"))

nit <- ggplot(nmds_comb %>% filter(is.na(d15N_anomaly_mean_1800_1850)==F), 
              aes(x = d15N_anomaly_mean_1800_1850, y = NMDS, color = lake_name)) +
  facet_grid(trophic_level ~ state) +
  geom_point() +
  scale_color_manual(values = lake_colors) +
  custom_theme() + 
  scale_y_reverse() +
  scale_x_reverse() + 
  labs(x=expression(delta^15 * "N anomaly from 1800-1850 mean"),
       color = "Lake") + 
        theme(strip.background = element_rect(fill = "white"),
               axis.title.y = element_blank(),
              axis.text.y = element_blank(),
               strip.text.y = element_blank())


# plot regression lines when significant
if (nrow(significant_models) > 0) {
  nit <- nit + geom_smooth(data = significant_models, 
                             method = "lm", color = "black", se = FALSE)
}

# add in r-squared to plot
nit <- nit + geom_text(data = model_stats, aes(x = x_pos, y = y_pos, label = label),
                         color = "black", size = 4, inherit.aes = FALSE)

#################
###### FISH #####
#################
# t-test for fish and fishless lakes, extracting p-value and t-tvalue to put on plot
t_test_results <- nmds_comb %>%
  group_by(trophic_level, state) %>%
  summarise(
    t_test = list(t.test(NMDS ~ fish_present_binary_YN, data = cur_data())),
    .groups = "drop"
  ) %>%
  mutate(
    p_value = sapply(t_test, function(x) x$p.value),  
    t_value = sapply(t_test, function(x) x$statistic),  # t-value
    sig_label = ifelse(p_value < 0.05, "*", ""),  
    y_sig = min(nmds_comb$NMDS, na.rm = TRUE) + 0.5,  #
    y_tval = 1.2,  
    t_label = paste0("t = ", round(t_value, 2)) 
  ) %>% filter(p_value < 0.05) 


# plot 
fish <- ggplot(nmds_comb, aes(x = factor(fish_present_binary_YN), 
                              y = NMDS, color = lake_name)) +
  facet_grid(trophic_level ~ state) +
  geom_point(position = position_jitter(width = 0.2)) + 
  geom_boxplot(aes(group = fish_present_binary_YN), color = "black", alpha = 0) +
  scale_color_manual(values = lake_colors) +
  custom_theme() + 
  scale_y_reverse() +
  labs(x = "Fish present", color = "Lake") +
  theme(strip.background = element_rect(fill = "white"),
        axis.title.y = element_blank(),
        axis.text.y = element_blank())

# add a star for signficant t-tests
fish <- fish + geom_text(data = t_test_results, aes(x = 1.5, y = y_sig, label = sig_label), 
                         color = "black", size = 8, fontface = "bold", inherit.aes = FALSE)

# add the t-value
fish <- fish + geom_text(data = t_test_results, aes(x = 1.5, y = y_tval, label = t_label), 
                         color = "black", size = 4, inherit.aes = FALSE)


(temp + nit + fish) + 
  plot_layout(guides = "collect") & 
  theme(legend.position = "right") &
  guides(color = guide_legend(override.aes = list(size = 5)))  


ggsave("3_Figures/SFigX_NMDS_state_stressor_trophiclevel.png", height=6, width=16, units="in")
```




### ii. max NMDS and stressor max
by state only
```{r}
# combine all three of the NMDS data frames
nmds_comb <-rbind(read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/NMDS_phyto.csv", header=T, row.names = 1) %>% 
                   select(sample_id, MDS2,d15N_anomaly_mean_1800_1850, mean_air_temp_degC_anomaly_combined, fish_present_binary_YN) %>% 
                   rename(NMDS=MDS2) %>% 
                   mutate(trophic_level="Phytoplankton"),

 
           read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/NMDS_hetero_prot.csv", header=T, row.names = 1) %>% 
                   select(sample_id, MDS2,d15N_anomaly_mean_1800_1850, mean_air_temp_degC_anomaly_combined, fish_present_binary_YN) %>%
                   rename(NMDS=MDS2) %>% 
                   mutate(trophic_level="Heterotrophic\nprotists"),

 
           read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/NMDS_zoop.csv", header=T, row.names = 1) %>% 
                   select(sample_id, MDS1, d15N_anomaly_mean_1800_1850, mean_air_temp_degC_anomaly_combined, fish_present_binary_YN) %>%
                   rename(NMDS=MDS1) %>% 
                   mutate(trophic_level="Zooplankton")
           )

# add in lake name and state
nmds_comb <- left_join(nmds_comb, metadata %>% select(sample_id, lake_name, state, mid_cm), join_by(sample_id)) 

nmds_comb$lake_name <- factor(nmds_comb$lake_name, levels = names(lake_colors))
nmds_comb$state <- factor(nmds_comb$state, levels = c("Washington", "Wyoming","California"))
nmds_comb$trophic_level <- factor(nmds_comb$trophic_level, levels = c("Phytoplankton", "Heterotrophic\nprotists", "Zooplankton"))

nmds_comb <- nmds_comb %>% arrange(trophic_level, lake_name, desc(mid_cm))

nmds_comb <- nmds_comb %>% group_by(state, trophic_level) %>% 
        summarize(nmds_max = max(NMDS)-min(NMDS),
                  nit_max = max(d15N_anomaly_mean_1800_1850, na.rm=T) - min(d15N_anomaly_mean_1800_1850, na.rm=T),
                  temp_max = max(mean_air_temp_degC_anomaly_combined) - min(mean_air_temp_degC_anomaly_combined)) 

#%>% left_join(.,metadata %>% select(lake_name, state, fish) %>% distinct(.), join_by(lake_name))

state_colors <- c("Washington" = "orange",
                  "Wyoming" = "#008080",
                  "California" = "#5D478B")

nmds_comb$state<-factor(nmds_comb$state, levels=names(state_colors))

temp<-ggplot(nmds_comb, aes(x=temp_max,y=nmds_max, color=state))+
        facet_grid(~trophic_level)+
        geom_point(size=4)+ 
        scale_color_manual(values=state_colors) +
        custom_theme() +
        labs(x="Maximum change in average annual air temperature
anomaly from 1951-1980 mean (deg C)",
        y="Maximum change in NMDS",
             color="State")+ 
        theme(strip.background = element_rect(fill = "white"),
               strip.text.y = element_blank())

nit<-ggplot(nmds_comb, aes(x=nit_max,y=nmds_max, color=state))+
        facet_grid(~trophic_level)+
        geom_point(size=4)+ 
        scale_color_manual(values=state_colors) +
        custom_theme()+
        labs(x=expression("Maximum difference " * delta^15 * "N anomaly from 1800-1850 mean"),
        y="Maximum change in NMDS",
             color="State") +
        theme(strip.background = element_rect(fill = "white"),
               axis.title.y = element_blank(),
              axis.text.y = element_blank(),
               strip.text.y = element_blank())


# fish <- ggplot(nmds_comb, aes(x = factor(fish), y = nmds_max, color = state)) +
#         facet_grid(~trophic_level)+
#         geom_point(size=4)+ 
#          scale_color_manual(values = state_colors) +
#         custom_theme() + 
#         labs(x = "Fish present",
#         y="NMDS (difference)",
#         color = "State") +
#         scale_x_discrete(labels = c("0" = "No", "1" = "Yes")) + 
#         theme(strip.background = element_rect(fill = "white"),
#                axis.title.y = element_blank(),
#               axis.text.y = element_blank())

(temp + nit ) + 
  plot_layout(guides = "collect") & 
  theme(legend.position = "right") &
  guides(color = guide_legend(override.aes = list(size = 5)))  


ggsave("3_Figures/FigX_max_NMDS_max_stressor_state_only.png", height=3, width=14, units="in")
```



## b. LME model summaries
Fish and fishless plotted separately
average all taxa
```{r}
sig_lme<-rbind(
        read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/V9_LME_phytoplankton_model_output_no_interactions.csv", header=T, row.names=1) %>% mutate(trophic_level="Phytoplankton"),
        
        read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/V9_LME_heterotrophic_protists_model_output_no_interactions.csv", header=T, row.names=1) %>% mutate(trophic_level="Heterotrophic protists"),
        
        read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/V9_LME_zooplankton_model_output_no_interactions.csv", header=T, row.names=1) %>% mutate(trophic_level="Zooplankton")
) %>% 
        
mutate(Value=abs(Value)) %>% # make absolute value
group_by(trophic_level, term, fish) %>% # group by trophic level and term (regardless of fish or fishless LMEs)
summarize(mean_effect=mean(Value)) %>% ungroup() # calculate the mean effect for each trophic level and stressor (term)


# order trophic level, term, and fish
sig_lme$trophic_level<-factor(sig_lme$trophic_level, levels=c("Phytoplankton", "Heterotrophic protists", "Zooplankton"))

sig_lme$term<-factor(sig_lme$term, levels=c("Air temperature", "Nitrogen deposition","Fish"))

sig_lme$fish<-factor(sig_lme$fish, levels=c("Fishless", "Fish"))

ggplot(sig_lme, aes(x = factor(term), y = mean_effect)) +
  geom_bar(stat = "identity") +
  facet_grid2(fish~trophic_level,  strip = strip_themed(
      background_x = elem_list_rect(fill = c("#33B58C","#85CFFF","#E07B33")),
      background_y = elem_list_rect(fill = "white"))) +
  theme_minimal() +
  labs(
    x = "Anthropogenic stressor",
    y = "Mean absolute effect") + custom_theme() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggsave("3_Figures/FigX_LME_summary_fish.png", height=5, width=8, units="in")
```


## c. clustered relative abundances 
```{r}
## PHYTOPLANKTON AND HETEROTROPHIC PROTISTS
# read in the functional assignment file remove ~4k taxa that assign to fungi
tax_fun<-read.csv("2_DataAnalysis/V9_Taxonomy_Function.csv", header=T, row.names=1) %>% column_to_rownames(.,var="asv_code") %>%  mutate(trophic_mode = replace_na(trophic_mode, "unknown")) %>% filter(!subdivision=="Fungi")
tax_fun <- as.matrix(tax_fun) # convert to matrix
ps_V9_norm_sub<-ps_V9_norm
tax_table(ps_V9_norm_sub) <- tax_table(tax_fun) # replace taxonomy table in the phyloseq object
rm(tax_fun)


ps_V9_norm_phyto<-subset_taxa(ps_V9_norm_sub, trophic_mode %in%c("phototrophs","phototrophs/mixotrophs","mixotrophs") | trophic_mode =="unknown" & subdivision%in%c("Cryptophyta_X", "Dinoflagellata", "Gyrista", "Haptophyta_X"))
# group by taxonomic rank and turn to relative abundance
sub <- ps_V9_norm_phyto %>% tax_glom(.,taxrank="subdivision") %>% transform_sample_counts(., function(x) x / sum(x)) %>% psmelt(.)

# subset dataset by taxa with the highest abundance in each group
sub <- sub %>% filter(subdivision%in%c(
        sub %>% filter(Abundance > 0.35) %>% select(subdivision) %>% unique(.) %>% pull() # this is where you select the abundance
        ))

# rename the groups so there isn't an _X
sub <- sub %>% mutate(subdivision= case_when(subdivision=="Chlorophyta_X" ~ "Chlorophyta",
                                             subdivision=="Streptophyta_X" ~ "Streptophyta",
                                             TRUE~subdivision
                                             ))


all_trophic<-sub %>% mutate(taxonomic_group=subdivision, trophic_level="Phytoplankton") %>% select(-subdivision)

ps_V9_norm_hetero<- subset_taxa(ps_V9_norm_sub, 
  (!trophic_mode %in% c("phototrophs", "phototrophs/mixotrophs", "mixotrophs") & 
   !(subdivision == "Metazoa" & class != "Rotifera")) & 
  !(trophic_mode == "unknown" & !subdivision %in% c("Alveolata_X", "Cercozoa", "Chrompodellids", "Discoba_X", "Euglenozoa", "Stramenopiles_X", "Colponemidia", "Foraminifera", "Hemimastigophora_X", "Nibbleridia_X")))

# group by taxonomic rank and turn to relative abundance
sub <- ps_V9_norm_hetero %>% tax_glom(.,taxrank="subdivision") %>% transform_sample_counts(., function(x) x / sum(x)) %>% psmelt(.)

# subset dataset by taxa with the highest abundance in each group
sub <- sub %>% filter(subdivision%in%c(
        sub %>% filter(Abundance > 0.55) %>% select(subdivision) %>% unique(.) %>% pull() # this is where you select the abundance
        ))

unique(sub$subdivision)

# rename the groups so there isn't an _X
sub <- sub %>% mutate(subdivision= case_when(subdivision=="Evosea_X" ~ "Evosea",
                                             subdivision=="Metazoa" ~ "Rotifera",
                                             TRUE~subdivision
                                             ))

all_trophic<-sub %>% mutate(taxonomic_group=subdivision, trophic_level="Heterotrophic protists")%>% select(-subdivision) %>% rbind(all_trophic,.)

# remove other taxonomic levels aside from taxonomic_group
all_trophic <- all_trophic %>% select(-c(domain,supergroup,division))

# ZOOPLANKTON
# read in taxonomy assigned in Ch. 2
tax_blast<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/ZooplanktonSedDNA/5_DataAnalysis/BLAST_zooplankton/Max_Bra/5_BLAST_V9_original_single_multiple_updated.csv", row.names=1,na.strings="") %>% column_to_rownames(., var="qseqid") %>% 
   mutate(taxonomic_group = replace_na(taxonomic_group, "Unassigned")) %>% select(Kingdom,taxonomic_group)
tax_blast <- as.matrix(tax_blast) # convert to matrix
ps_V9_norm_sub<-ps_V9_norm
tax_table(ps_V9_norm_sub) <- tax_table(tax_blast) # replace taxonomy table in the phyloseq object
rm(tax_blast)

# congomerate right away to taxonomic_group
ps_V9_norm_zoop <- ps_V9_norm_sub %>% tax_glom(., taxrank = "taxonomic_group")


# group by taxonomic rank and turn to relative abundance
sub <- ps_V9_norm_zoop %>% transform_sample_counts(., function(x) x / sum(x)) %>% psmelt(.)

# subset dataset by taxa with the highest abundance in each group
sub <- sub %>% filter(taxonomic_group%in%c(
        sub %>% filter(Abundance > 0.4) %>% select(taxonomic_group) %>% unique(.) %>% pull() # this is where you select the abundance
        ))

unique(sub$taxonomic_group)

sub <- sub %>% select(-Kingdom)

all_trophic <- sub  %>% mutate(trophic_level="Zooplankton") %>% rbind(all_trophic,.)


all_trophic <-all_trophic %>% select(Abundance,mean_air_temp_degC_anomaly_combined,d15N_anomaly_mean_1800_1850,fish_present_binary,lake_name,taxonomic_group, mid_cm, fish, trophic_level, date_mid_AD_combo, state) %>% arrange(trophic_level, taxonomic_group,lake_name,desc(mid_cm)) %>% group_by(lake_name, taxonomic_group) %>% mutate(time_seq=row_number()) %>% ungroup() %>% mutate(abundance=Abundance) %>% select(-Abundance) %>% 
        mutate(trophic_level_tax_group=paste(trophic_level,taxonomic_group, sep=" - "))

# change skelton to be in the fishless lake category for the "fish" column
all_trophic <- all_trophic %>% mutate(fish=case_when(lake_name=="Skelton"~0,
                                                     !lake_name=="Skelton"~fish))

# factor lake name to match the lake colors
all_trophic$lake_name<-factor(all_trophic$lake_name, levels=names(lake_colors))

lake_colors_fish <- c("Crescent" = "goldenrod3", 
                 "Canyon" = "goldenrod3", 
                 "Eyrie" = "goldenrod3",
                 "Lightning" = "goldenrod3",
                 "Soldier" = "goldenrod3", 
                 "Skelton" = "goldenrod3", 
                  "Louise" = "#5D478B",
                 "Monogram" = "#5D478B",
                 "Scott" = "#5D478B",
                 "Black Rock" = "#5D478B",
                 "Footprint" = "#5D478B",
                 "Lost" = "#5D478B",
                 "Bullfrog" = "#5D478B",
                 "Middle Gaylor"= "#5D478B")

all_trophic$lake_name_fish<-factor(all_trophic$lake_name, levels=names(lake_colors_fish))


all_trophic$state<-factor(all_trophic$state, levels=c("Washington","Wyoming","California"))


# subset by taxa with significant LME results and effects greater than abs(0.04)
clust_tax<-rbind(
        read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/V9_LME_phytoplankton_model_output_no_interactions.csv", header=T, row.names=1) %>% filter(pval0.5=="Yes") %>% mutate(trophic_level="Phytoplankton"),
        
        read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/V9_LME_heterotrophic_protists_model_output_no_interactions.csv", header=T, row.names=1) %>% filter(pval0.5=="Yes") %>% mutate(trophic_level="Heterotrophic protists"),
        
        read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/V9_LME_zooplankton_model_output_no_interactions.csv", header=T, row.names=1) %>% filter(pval0.5=="Yes") %>% mutate(trophic_level="Zooplankton")) %>% 
        # select taxa that have an effect greater than 0.4
        filter(Value > 0.04 | Value < (-0.04)) %>%
        select(taxa) %>% distinct(.) %>% pull()
        
all_trophic_top <- all_trophic %>% filter(taxonomic_group %in% clust_tax)

# remove extra objects
rm(sub);rm(ps_V9_norm_hetero);rm(ps_V9_norm_phyto);rm(ps_V9_norm_sub); rm(ps_V9_norm_zoop); rm(clust_tax)
```

Averages overall for top taxa
```{r}
all_trophic_top$trophic_level_tax_group <- factor(
        all_trophic_top$trophic_level_tax_group,
        levels = c(
                "Phytoplankton - Chlorophyta",
                "Phytoplankton - Streptophyta",
                "Phytoplankton - Gyrista",
                "Phytoplankton - Dinoflagellata",
                "Heterotrophic protists - Ciliophora",
                "Zooplankton - Leptodiaptomus",
                "Zooplankton - Hesperodiaptomus",
                "Zooplankton - Daphnia spp."))

avg_lake_50yrs<-all_trophic_top %>% 
        mutate(date_window_50yrs=cut(date_mid_AD_combo,
                        breaks = seq(1400, 2050, by = 50),
                        right=F, # intervals are left closed [1400,1450)
                        labels = paste(seq(1400, 2000, by = 50), 
                                       seq(1449, 2049, by = 50), sep = "-")))%>%
       group_by(trophic_level_tax_group, date_window_50yrs) %>% 
        summarize(avg_abund=mean(abundance),
                  median_year = median(as.numeric(unlist(strsplit(unique(as.character(date_window_50yrs)), "-"))))) %>%
        ungroup() %>%
        # the relative abundance for prior to 1400 is listed as NA - so remove it here
        filter(complete.cases(.))




ggplot(data=all_trophic_top, aes(x=date_mid_AD_combo, y=abundance, color=lake_name))+
        facet_wrap(~trophic_level_tax_group)+
        geom_line() + 
        geom_line(data=avg_lake_50yrs, aes(x=median_year, y=avg_abund, color=NULL), linewidth=2, color="black")+
        custom_theme()+
        labs(color="Lake",
             y="Relative abundance (proportion)",
             x="Date (Common Era)")+
        scale_color_manual(values=lake_colors)

ggsave("3_Figures/FigX_clustered_rel_abund_lake_top.png", height=10, width=20, units="in")
```

Averages overall for all taxa 
```{r}
all_trophic$trophic_level_tax_group <- factor(
        all_trophic$trophic_level_tax_group,
        levels = c(
                "Phytoplankton - Chlorophyta"         ,
                "Phytoplankton - Dinoflagellata"      ,
                "Phytoplankton - Gyrista"             ,
                "Phytoplankton - Streptophyta"        ,
                "Heterotrophic protists - Cercozoa"   ,
                "Heterotrophic protists - Ciliophora" ,
                "Heterotrophic protists - Eumycetozoa",
                "Heterotrophic protists - Evosea"     ,
                "Heterotrophic protists - Perkinsea"  ,
                "Heterotrophic protists - Rotifera"   ,
                "Zooplankton - Bosmina"               ,
                "Zooplankton - Chydoridae"            ,
                "Zooplankton - Cyclopidae"            ,
                "Zooplankton - Daphnia pulex"         ,
                "Zooplankton - Daphnia spp."          ,
                "Zooplankton - Hesperodiaptomus"      ,
                "Zooplankton - Holopedium"            ,
                "Zooplankton - Leptodiaptomus"
        )
)

avg_lake_50yrs<-all_trophic %>% 
        mutate(date_window_50yrs=cut(date_mid_AD_combo,
                        breaks = seq(1400, 2050, by = 50),
                        right=F, # intervals are left closed [1400,1450)
                        labels = paste(seq(1400, 2000, by = 50), 
                                       seq(1449, 2049, by = 50), sep = "-")))%>%
       group_by(trophic_level_tax_group, date_window_50yrs) %>% 
        summarize(avg_abund=mean(abundance),
                  median_year = median(as.numeric(unlist(strsplit(unique(as.character(date_window_50yrs)), "-"))))) %>%
        ungroup() %>%
        # the relative abundance for prior to 1400 is listed as NA - so remove it here
        filter(complete.cases(.))


ggplot(data=all_trophic, aes(x=date_mid_AD_combo, y=abundance, color=lake_name))+
  facet_wrap2(~ trophic_level_tax_group, nrow = 5, ncol = 4,
              strip = strip_themed(
                background_x = elem_list_rect(fill = c(rep("#33B58C", 4), rep("#85CFFF", 6), rep("#E07B33", 8))))) +
        geom_line() + 
        geom_line(data=avg_lake_50yrs, aes(x=median_year, y=avg_abund, color=NULL), linewidth=2, color="black")+
        custom_theme()+
        labs(color="Lake",
             y="Relative abundance (proportion)",
             x="Date (Common Era)")+
        scale_color_manual(values=lake_colors)+
        guides(color = guide_legend(override.aes = list(linewidth = 2))) 


ggsave("3_Figures/FigX_clustered_rel_abund_lake_all.png", height=10, width=20, units="in")
```

### i. Stats for ms - phytoplankton
```{r}
phyto_LME<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/PhytoZoopSedDNA/2_DataAnalysis/V9_LME_phytoplankton_model_output_no_interactions.csv", header=T, row.names=1) %>% filter(pval0.5=="Yes") %>%  mutate(across(where(is.numeric), ~ round(.x, 3)))

## Chlorophyta ##

# Look at overall abundance over time
avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Chlorophyta")

# average high prior to 1850
avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Chlorophyta" & median_year < 1850) %>% pull(avg_abund) %>% mean(.) %>% round(.,digits=3) %>%   `*`(100) 
#[1] 46.8

# to low around 2000
avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Chlorophyta" & median_year > 1850) %>% pull(avg_abund) %>% min(.) %>% round(.,digits=3) %>%   `*`(100) 
#[1] 46.8

phyto_LME %>% filter(taxa=="Chlorophyta") %>% select(term, Value, fish)
#                  term  Value     fish
# 1     Air temperature -0.085 Fishless
# 2 Nitrogen deposition -0.061 Fishless
# 3 Nitrogen deposition -0.029     Fish
# 4                Fish -0.104     Fish



## Dinoflagellata ##

# Look at overall abundance over time
avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Dinoflagellata")

# average low prior to 18 decline around 1900
avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Dinoflagellata" & median_year < 1900) %>% pull(avg_abund) %>% mean(.) %>% round(.,digits=3) %>%   `*`(100) 
#[1] 12.7

avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Dinoflagellata" & median_year > 1900) %>% pull(avg_abund) %>% max(.) %>% round(.,digits=3) %>%   `*`(100) 
#[1] 31.8

phyto_LME %>% filter(taxa=="Dinoflagellata") %>% select(term, Value, fish)
#                  term Value     fish
# 1 Nitrogen deposition 0.046 Fishless
# 2 Nitrogen deposition 0.063     Fish


## Gyrista ##

# Look at overall abundance over time
avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Gyrista")

# average low prior to 18 decline around 1900
avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Gyrista" & median_year < 1900) %>% pull(avg_abund) %>% mean(.) %>% round(.,digits=3) %>%   `*`(100) 
#[1]  23.5

avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Gyrista" & median_year > 1900) %>% pull(avg_abund) %>% max(.) %>% round(.,digits=3) %>%   `*`(100) 
#[1] 49.4

phyto_LME %>% filter(taxa=="Gyrista") %>% select(term, Value, fish)
#              term Value     fish
# 1 Air temperature 0.078 Fishless
# 2            Fish 0.085     Fish


## Streptophyta ##

# Look at overall abundance over time
avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Streptophyta")

# average low prior to 18 decline around 1900
avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Streptophyta" & median_year < 1900) %>% pull(avg_abund) %>% mean(.) %>% round(.,digits=3) %>%   `*`(100) 
#[1]  17.0

avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Streptophyta" & median_year > 1900) %>% pull(avg_abund) %>% min(.) %>% round(.,digits=3) %>%   `*`(100) 
#[1]  0.8

phyto_LME %>% filter(taxa=="Streptophyta") %>% select(term, Value, fish)
#                  term  Value     fish
# 1 Nitrogen deposition -0.042 Fishless
# 2 Nitrogen deposition -0.032     Fish

```

### ii. Stats for ms - heterotrophic protists and rotifers
```{r}

```



Averages by fish status
```{r}
all_trophic_top$trophic_level_tax_group <- factor(
        all_trophic_top$trophic_level_tax_group,
        levels = c(
                "Phytoplankton - Chlorophyta",
                "Phytoplankton - Streptophyta",
                "Phytoplankton - Gyrista",
                "Phytoplankton - Dinoflagellata",
                "Heterotrophic protists - Ciliophora",
                "Zooplankton - Leptodiaptomus",
                "Zooplankton - Hesperodiaptomus",
                "Zooplankton - Daphnia spp."))


avg_lake_50yrs<-all_trophic_top %>% 
        mutate(date_window_50yrs=cut(date_mid_AD_combo,
                        breaks = seq(1400, 2050, by = 50),
                        right=F, # intervals are left closed [1400,1450)
                        labels = paste(seq(1400, 2000, by = 50), 
                                       seq(1449, 2049, by = 50), sep = "-")))%>%
       group_by(trophic_level_tax_group, date_window_50yrs, fish) %>% 
        summarize(avg_abund=mean(abundance),
                  median_year = median(as.numeric(unlist(strsplit(unique(as.character(date_window_50yrs)), "-"))))) %>%
        ungroup() %>% 
        # the relative abundance for prior to 1400 is listed as NA - so remove it here
        filter(complete.cases(.))


ggplot(data=all_trophic_top, aes(x=date_mid_AD_combo, y=abundance, color=lake_name_fish))+
        facet_wrap2(~ trophic_level_tax_group, nrow = 4, ncol = 2,
                    strip = strip_themed(
    background_x = elem_list_rect(fill = c(rep("#33B58C",4), rep("#85CFFF",1), rep("#E07B33",3)))))+
        geom_line(alpha = 0.6) + 
        geom_line(data=avg_lake_50yrs %>% filter(fish==1), aes(x=median_year, y=avg_abund, color=NULL), linewidth=2, color="#5D478B")+
        geom_line(data=avg_lake_50yrs %>% filter(fish==0), aes(x=median_year, y=avg_abund, color=NULL), linewidth=2, color="goldenrod3")+
        custom_theme()+
        labs(color="Lake",
             y="Relative abundance (proportion)",
             x="Date (Common Era)")+
        scale_color_manual(values=lake_colors_fish)+
        theme(legend.position = "none")


ggsave("3_Figures/FigX_clustered_rel_abund_lake_fish_top.png", height=6.5, width=7, units="in")




# # just make the legend for cropping
# legend_data <- data.frame(
#   fish_status = c("Fish", "Fishless"),
#   x = c(min(all_trophic$date_mid_AD_combo) - 100, min(all_trophic$date_mid_AD_combo) - 100),
#   y = c(min(all_trophic$abundance) - 10, min(all_trophic$abundance) - 10)
# )
# 
# ggplot(data = all_trophic, aes(x = date_mid_AD_combo, y = abundance, color = lake_name_fish)) +
#   facet_wrap2(~ trophic_level_tax_group, nrow = 10, ncol = 2,
#               strip = strip_themed(
#                 background_x = elem_list_rect(fill = c(rep("#33B58C",4), rep("#85CFFF",1), rep("#E07B33",3)))
#               )) +
#   geom_line(alpha = 0.6) +
#   # Add Fish & Fishless lines (without affecting color legend)
#   geom_line(data = avg_lake_50yrs %>% filter(fish == 1), aes(x = median_year, y = avg_abund),
#             linewidth = 2, color = "#5D478B") +
#   geom_line(data = avg_lake_50yrs %>% filter(fish == 0), aes(x = median_year, y = avg_abund),
#             linewidth = 2, color = "goldenrod3") +
#   # Add dummy lines for the legend
#   geom_line(data = legend_data, aes(x = x, y = y, color = fish_status), linewidth = 2) +
#   custom_theme() +
#   labs(color = "", y = "Relative abundance (proportion)", x = "Date (Common Era)") +
#   scale_color_manual(
#     values = c(lake_colors_fish, "Fishless" = "goldenrod3","Fish" = "#5D478B"),
#     breaks = c( "Fishless","Fish")
#   ) +
#   guides(color = guide_legend(override.aes = list(linetype = 1, size = 2)))
# ggsave("3_Figures/FigX_clustered_rel_abund_lake_fish_avg_50yrs_legend.png", height=5, width=6, units="in")
```


Averages by state - top taxa
```{r}
all_trophic_top$trophic_level_tax_group <- factor(
        all_trophic_top$trophic_level_tax_group,
        levels = c(
                "Phytoplankton - Chlorophyta",
                "Phytoplankton - Streptophyta",
                "Phytoplankton - Gyrista",
                "Phytoplankton - Dinoflagellata",
                "Heterotrophic protists - Ciliophora",
                "Zooplankton - Leptodiaptomus",
                "Zooplankton - Hesperodiaptomus",
                "Zooplankton - Daphnia spp."))

avg_lake_50yrs<-all_trophic_top %>% 
        mutate(date_window_50yrs=cut(date_mid_AD_combo,
                        breaks = seq(1400, 2050, by = 50),
                        right=F, # intervals are left closed [1400,1450)
                        labels = paste(seq(1400, 2000, by = 50), 
                                       seq(1449, 2049, by = 50), sep = "-")))%>%
       group_by(trophic_level_tax_group, date_window_50yrs, state) %>% 
        summarize(avg_abund=mean(abundance),
                  median_year = median(as.numeric(unlist(strsplit(unique(as.character(date_window_50yrs)), "-"))))) %>% 
        ungroup() %>% 
        # the relative abundance for prior to 1400 is listed as NA - so remove it here
        filter(complete.cases(.))




ggplot(data = all_trophic_top, aes(x = date_mid_AD_combo, y = abundance, color = lake_name)) +
  facet_wrap2(~ trophic_level_tax_group, nrow = 4, ncol = 2,
              strip = strip_themed(
                background_x = elem_list_rect(fill = c(rep("#33B58C", 4), rep("#85CFFF", 1), rep("#E07B33", 3))))) +
  geom_line(alpha = 0.6) +
    geom_line(data = avg_lake_50yrs, aes(x = median_year, y = avg_abund, color = state), linewidth = 2) +
  custom_theme() +
  labs(color = "Lake (transparent)
and state (solid)",
       y = "Relative abundance (proportion)",
       x = "Date (Common Era)") +
  scale_color_manual(values = c(lake_colors, 
                                "Washington" = "orange",
                                "Wyoming" = "#008080",
                                "California" = "#5D478B")) + 
  guides(color = guide_legend(override.aes = list(linewidth = 2))) 



ggplot(data = all_trophic_top %>% filter(trophic_level_tax_group=="Phytoplankton - Chlorophyta"), aes(x = date_mid_AD_combo, y = abundance, color = lake_name)) +
  geom_line(alpha = 0.6) +
    geom_line(data = avg_lake_50yrs %>% filter(trophic_level_tax_group=="Phytoplankton - Chlorophyta"), aes(x = median_year, y = avg_abund, color = state), linewidth = 2) +
  custom_theme() +
  labs(color = "Lake (transparent)
and state (solid)",
       y = "Relative abundance (proportion)",
       x = "Date (Common Era)") +
  scale_color_manual(values = c(lake_colors, 
                                "Washington" = "orange",
                                "Wyoming" = "#008080",
                                "California" = "#5D478B")) + 
  guides(color = guide_legend(override.aes = list(linewidth = 2))) 



ggsave("3_Figures/FigX_clustered_rel_abund_lake_state_top.png", height=6.5, width=9,  units="in")

```



Averages by state - all taxa
```{r}
all_trophic$trophic_level_tax_group <- factor(
        all_trophic$trophic_level_tax_group,
        levels = c(
                "Phytoplankton - Chlorophyta"         ,
                "Phytoplankton - Dinoflagellata"      ,
                "Phytoplankton - Gyrista"             ,
                "Phytoplankton - Streptophyta"        ,
                "Heterotrophic protists - Cercozoa"   ,
                "Heterotrophic protists - Ciliophora" ,
                "Heterotrophic protists - Eumycetozoa",
                "Heterotrophic protists - Evosea"     ,
                "Heterotrophic protists - Perkinsea"  ,
                "Heterotrophic protists - Rotifera"   ,
                "Zooplankton - Bosmina"               ,
                "Zooplankton - Chydoridae"            ,
                "Zooplankton - Cyclopidae"            ,
                "Zooplankton - Daphnia pulex"         ,
                "Zooplankton - Daphnia spp."          ,
                "Zooplankton - Hesperodiaptomus"      ,
                "Zooplankton - Holopedium"            ,
                "Zooplankton - Leptodiaptomus"
        )
)

avg_lake_50yrs<-all_trophic %>% 
        mutate(date_window_50yrs=cut(date_mid_AD_combo,
                        breaks = seq(1400, 2050, by = 50),
                        right=F, # intervals are left closed [1400,1450)
                        labels = paste(seq(1400, 2000, by = 50), 
                                       seq(1449, 2049, by = 50), sep = "-")))%>%
       group_by(trophic_level_tax_group, date_window_50yrs, state) %>% 
        summarize(avg_abund=mean(abundance),
                  median_year = median(as.numeric(unlist(strsplit(unique(as.character(date_window_50yrs)), "-"))))) %>% 
        ungroup() %>% 
        # the relative abundance for prior to 1400 is listed as NA - so remove it here
        filter(complete.cases(.))



ggplot(data = all_trophic, aes(x = date_mid_AD_combo, y = abundance, color = lake_name)) +
  facet_wrap2(~ trophic_level_tax_group, nrow = 5, ncol = 4,
              strip = strip_themed(
                background_x = elem_list_rect(fill = c(rep("#33B58C", 4), rep("#85CFFF", 6), rep("#E07B33", 8))))) +
  geom_line(alpha = 0.6) +
    geom_line(data = avg_lake_50yrs, aes(x = median_year, y = avg_abund, color = state), linewidth = 2) +
  custom_theme() +
  labs(color = "Lake (transparent)
and state (solid)",
       y = "Relative abundance (proportion)",
       x = "Date (Common Era)") +
  scale_color_manual(values = c(lake_colors, 
                                "Washington" = "orange",
                                "Wyoming" = "#008080",
                                "California" = "#5D478B")) + 
  guides(color = guide_legend(override.aes = list(linewidth = 2))) 


ggsave("3_Figures/FigX_clustered_rel_abund_lake_state_all.png", height=10, width=20, units="in")

```
